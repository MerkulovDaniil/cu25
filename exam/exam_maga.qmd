---
format: 
    pdf:
        pdf-engine: xelatex
        include-in-header: ../files/exam_header.tex  # Custom LaTeX commands and preamble
---

# Определения и формулировки

1. Положительно определённая матрица.
1. Евклидова норма вектора.
<!-- 1. Неравенство треугольника для нормы. -->
1. $p$-норма вектора.
1. Как выглядит единичный шар в $p$ - норме на плоскости для $p=1,2,\infty$?
1. Норма Фробениуса для матрицы.
1. Спектральная норма матрицы.
1. Скалярное произведение двух векторов.
1. Скалярное произведение двух матриц, согласованное с нормой Фробениуса.
1. Собственные значения матрицы. Спектр матрицы.
1. Связь спектра матрицы и её определенности.
1. Спектральное разложение матрицы.
1. Сингулярное разложение матрицы.
1. Связь определителя и собственных чисел для квадратной матрицы.
1. Связь следа и собственных чисел для квадратной матрицы.
1. Линейная сходимость последовательности. 
1. Сублинейная сходимость последовательности. 
1. Сверхлинейная сходимость последовательности. 
1. Квадратичная сходимость последовательности.
1. Рассмотрим итеративный процесс $x_k \in \mathbb{R}$, сходящийся к решению $x^* \in \mathbb{R}$ квадратично. Как изменяется количество верных значащих цифр в решении после одной итерации метода?
1. Формулировка теста корней для определения скорости сходимости последовательности.
<!-- 1. Формулировка теста отношений для определения скорости сходимости последовательности. -->
1. Унимодальная функция.
1. Метод дихотомии.
1. Метод золотого сечения.
<!-- 1. Метод параболической интерполяции. -->
1. Условие достаточного убывания для неточного линейного поиска.
1. Условия Гольдштейна для неточного линейного поиска.
1. Условие ограничения на кривизну для неточного линейного поиска.
1. Градиент функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Гессиан функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Якобиан функции $f(x): \mathbb{R}^n \to \mathbb{R}^m$.
1. Формула для аппроксимации Тейлора первого порядка $f^I_{x_0}(x)$ функции $f(x): \mathbb{R}^n \to \mathbb{R}$ в точке $x_0$.
1. Формула для аппроксимации Тейлора второго порядка $f^{II}_{x_0}(x)$ функции $f(x): \mathbb{R}^n \to \mathbb{R}$ в точке $x_0$.
1. Связь дифференциала функции $df$ и градиента $\nabla f$ для функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Связь второго дифференциала функции $d^2f$ и гессиана $\nabla^2 f$ для функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Формула для приближенного вычисления производной функции $f(x): \mathbb{R}^n \to \mathbb{R}$ по $k$-ой координате с помощью метода конечных разностей.
<!-- 1. Пусть $f = f(x_1(t), \ldots, x_n(t))$. Формула для вычисления $\frac{\partial f}{\partial t}$ через $\frac{\partial x_i}{\partial t}$ (Forward chain rule). -->
<!-- 1. Пусть $L$ - функция, возвращающая скаляр, а $v_k$ - функция, возвращающая вектор $x \in \mathbb{R}^t$. Формула для вычисления $\frac{\partial L}{\partial v_k}$ через $\frac{\partial L}{\partial x_i}$ (Backward chain rule). -->
<!-- 1. Идея Хатчинсона для оценки следа матрицы с помощью matvec операций. -->
1. Афинное множество. Афинная комбинация. Афинная оболочка.
1. Выпуклое множество. Выпуклая комбинация. Выпуклая оболочка.
1. Конус. Выпуклый конус. Коническая комбинация. Коническая оболочка.
<!-- 1. Внутренность множества.  -->
<!-- 1. Относительная внутренность множества. -->
1. Сумма Минковского.
1. Любые 2 операции с множествами, сохраняющие выпуклость.
1. Выпуклая функция.
<!-- 1. Строго выпуклая функция. -->
1. Надграфик функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
<!-- 1. Множество подуровней функции $f(x): \mathbb{R}^n \to \mathbb{R}$. -->
1. Дифференциальный критерий выпуклости первого порядка.
1. Дифференциальный критерий выпуклости второго порядка.
1. Связь выпуклости функции и её надграфика.
1. $\mu$-сильно выпуклая функция.
1. Дифференциальный критерий сильной выпуклости первого порядка.
1. Дифференциальный критерий сильной выпуклости второго порядка.
1. Любые 2 операции с функциями, сохраняющие выпуклость.
<!-- 1. Теорема Тейлора. -->
1. Необходимые условия локального экстремума.
1. Достаточные условия локального экстремума.
1. Общая задача математического программирования. Функция Лагранжа.
1. Теорема Каруша - Куна - Таккера в форме необходимых условий решения задачи математического программирования.
1. Условие Слейтера.
1. Задача выпуклого программирования.
<!-- 1. Двойственная функция в задаче математического программирования. -->
<!-- 1. Двойственная задача для задачи математического программирования. -->
<!-- 1. Сильная двойственность. Зазор двойственности. -->
<!-- 1. Локальный анализ чувствительности с помощью множителей Лагранжа. -->
1. Задача линейного программирования. Задача линейного программирования в стандартной форме.
<!-- 1. Возможные случаи двойственности в задаче линейного программирования. -->
1. Идея симплекс метода.
<!-- 1. Нахождение первоначальной угловой точки с помощью двухфазного симплекс метода. -->
1. Сходимость симплекс метода.
<!-- 1. Формулировка задачи о максимальном потоке в графе. -->
<!-- 1. Формулировка задачи о минимальном разрезе в графе. -->
<!-- 1. Теорема о максимальном потоке и минимальном разрезе. -->
<!-- 1. Показать, что направление антиградиента - направление наискорейшего локального убывания функции. -->
<!-- 1. Дифференциальное уравнение градиентного потока. -->
1. Метод градиентного спуска.
1. Наискорейший спуск.
1. Как направлены две соседние итерации метода наискорейшего спуска по отношению друг к другу?
1. Липшицева парабола для гладкой функции.
1. Размер шага наискорейшего спуска для квадратичной функции.
<!-- 1. Характер сходимости градиентного спуска к локальному экстремуму для гладких невыпуклых функций в терминах $\mathcal{O}$ от числа итераций метода. -->
1. Характер сходимости градиентного спуска для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости градиентного спуска для гладких и сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Связь спектра гессиана с константами сильной выпуклости и гладкости функции.
1. Условие Поляка-Лоясиевича (градиентного доминирования) для функций.
1. Сходимость градиентного спуска для сильно выпуклых квадратичных функций. Оптимальные гиперпараметры.
1. Связь PL-функций и сильно выпуклых функций. 
1. Привести пример выпуклой, но не сильно выпуклой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Привести пример сильно выпуклой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Нижние оценки для гладкой выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода.
1. Нижние оценки для гладкой сильно выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода.
1. Отличие ускоренной и неускоренной линейной сходимости для методов первого порядка.
1. Метод тяжелого шарика (Поляка).
1. Понятие локальной и глобальной сходимости численного метода оптимизации.
1. Ускоренный градиентный метод Нестерова для выпуклых гладких функций.
1. Ускоренный градиентный метод Нестерова для сильно выпуклых гладких функций.
1. $A$-сопряженность двух векторов. $A$-ортогональность. Скалярное произведение $\langle \cdot, \cdot \rangle_A$.
<!-- 1. Процедура ортогонализации Грама-Шмидта. -->
<!-- 1. Метод сопряженных направлений. -->
<!-- 1. Метод сопряженных градиентов. -->
1. Зависимость сходимости метода сопряженных градиентнов от спектра матрицы.
<!-- 1. Характер сходимости метода сопряженных градиентов в терминах $\mathcal{O}$ от числа итераций метода. -->
<!-- 1. Метод Полака-Рибьера. -->
1. Метод Ньютона.
1. Сходимость метода Ньютона для квадратичной функции.
1. Характер сходимости метода Ньютона для сильно выпуклых гладких функций - куда и как сходится.
1. Демпфированный метод Ньютона.
1. Идея квазиньютоновских методов. Метод SR-1.
<!-- 1. Афинная инвариантность метода Ньютона. -->
1. Проекция.
1. Достаточное условие существования проекции точки на множество.
1. Достаточное условие единственности проекции точки на множество.
1. Метод проекции градиента.
<!-- 1. Критерий проекции точки на выпуклое множество (Неравенство Бурбаки-Чейни-Гольдштейна). -->
1. Проекция как нерастягивающий оператор.
1. Метод Франк-Вульфа.
1. Характер сходимости метода проекции градиента для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода проекции градиента для гладких сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода Франк-Вульфа для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода Франк-Вульфа для гладких сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
<!-- 1. Нижние оценки для условной оптимизации с помощью оракула линейной минимизации для сильно выпуклых гладких функций в терминах $\mathcal{O}$ от числа итераций метода. -->
1. Привести пример выпуклой негладкой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Субградиент. Субдифференциал.
1. Как считать субдифференциал поточечного максимума выпуклых функций.
1. Субградиентный метод.
1. Характер сходимости субградиентного метода для негладких выпуклых Липшицевых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Какому условию должна удовлетворять стратегия выбора шага, чтобы субградиентный метод сходился для выпуклых Липшицевых функций?
1. Характер сходимости субградиентного метода для негладких сильно выпуклых Липшицевых функций в терминах $\mathcal{O}$ от числа итераций метода. Стратегия выбора шага.
<!-- 1. Нижние оценки для негладкой выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода. -->
<!-- 1. Нижние оценки для негладкой сильно выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода. -->
<!-- 1. Проксимальный оператор. -->
<!-- 1. Оператор проекции как частный случай проксимального оператора. -->
<!-- 1. Характер сходимости проксимального градиентного метода для гладких выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода. -->
<!-- 1. Характер сходимости проксимального градиентного метода для гладких сильно выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода. -->
<!-- 1. Аналитическое выражение для $\text{prox}_{\lambda \|x\|_1}$. -->
<!-- 1. Аналитическое выражение для $\text{prox}_{\frac{\mu}{2} \|x\|_2^2}$. -->
<!-- 1. Проксимальный оператор как нерастягивающий оператор. -->
<!-- 1. Характер сходимости ускоренного проксимального градиентного метода для гладких выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода. -->
1. Метод стохастического градиентного спуска.
1. Идея мини-батча для метода стохастического градиентного спуска. Эпоха.
1. Характер сходимости стохастического градиентного спуска для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости стохастического градиентного спуска для гладких PL-функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер работы стохастического градиентного спуска с постоянным шагом для гладких PL-функций.
<!-- 1. Основная идея методов уменьшения дисперсии. -->
<!-- 1. Метод SVRG. -->
<!-- 1. Метод SAG. -->
<!-- 1. Метод Adagrad. -->
<!-- 1. Метод RMSProp. -->
<!-- 1. Метод Adadelta. -->
<!-- 1. Метод Adam. -->
<!-- 1. Метод AdamW. -->
<!-- 1. Метод Shampoo. -->
<!-- 1. Метод Muon. -->
<!-- 1. Как сравниваются методы в AlgoPerf Benchmark. -->
<!-- 1. Идея проекции функции потерь нейронной сети на прямую, плоскость. -->
1. Grokking.
1. Double Descent.
1. Взрыв/Затухание градиентов при обучении глубоких нейронных сетей.
1. Идея gradient checkpointing.
<!-- 1. Идея аккумуляции градиентов. -->
<!-- 1. Зачем увеличивать батч при обучении больших нейросетевых моделей. Warmup.  -->
<!-- 1. Идея cooldown фазы для построения расписания learning rate. В чём преимущество по сравнению с cosine scheduler?
1. Data Parallel обучение на нескольких видеокартах.
1. GPipe Pipeline параллелизм.
1. PipeDream Pipeline параллелизм.
1. Дообучение больших моделей с помощью LoRA адаптеров.
1. Сколько токенов в обучающей выборке приходилось на модель Chinchilla на один обучаемый параметр модели?
1. Метод двойственного градиентного подъема.
1. Связь константы сильной выпуклости $f$ и гладкости $f^*$.
1. Идея dual decomposition.
1. Метод двойственного градиентного подъема для линейных ограничений-неравенств.
1. Метод модифицированной функции Лагранжа.
1. Метод ADMM. -->
<!-- 1. Формулировка задачи линейных наименьших квадратов с $\ell_1$ регуляризацией в форме ADMM. -->
<!-- 1. Формулировка задачи поиска точки на пересечении двух выпуклых множеств в форме ADMM. -->