---
title: "Градиентный спуск. Теоремы сходимости в квадратичном случае. Теоремы сходимости в гладком случае (выпуклые, сильно выпуклые, PL)"
author: Даня Меркулов
institute: Оптимизация для всех! ЦУ
format: 
    beamer:
      pdf-engine: xelatex
      aspectratio: 169
      fontsize: 9pt
      section-titles: true
      incremental: true
      include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
    beamer-cu:
      pdf-engine: xelatex
      aspectratio: 169
      fontsize: 9pt
      section-titles: true
      incremental: true
      include-in-header: ../files/xeheader_cu.tex
      header-includes:
        - \newcommand{\cover}{../files/БАК_Методы вып_оптимизации_презентация_8.pdf}
    beamer-cu-maga:
      pdf-engine: xelatex
      aspectratio: 169
      fontsize: 9pt
      section-titles: true
      incremental: true
      include-in-header: ../files/xeheader_cu.tex
      header-includes:
        - \newcommand{\cover}{../files/Методы вып_оптимизации_презентация_8.pdf}
header-includes:
 - \newcommand{\bgimage}{../files/back9.jpeg}
---


# Сильно выпуклые квадратичные функции

## Сдвиг координат

:::: {.columns}

::: {.column width="70%"}

Рассмотрим следующую задачу квадратичной оптимизации:
$$
\label{problem}
\min\limits_{x \in \mathbb{R}^d} f(x) =  \min\limits_{x \in \mathbb{R}^d} \dfrac{1}{2} x^\top  A x - b^\top  x + c, \text{ где } A \in \mathbb{S}^d_{++}.
$$

. . .

* Во-первых, без ограничения общности мы можем установить $c = 0$, что не повлияет на процесс оптимизации.
* Во-вторых, у нас есть спектральное разложение матрицы $A = Q \Lambda Q^T$.
* Покажем, что мы можем сделать сдвиг координат, чтобы сделать анализ немного проще. Пусть $\hat{x} = Q^T(x - x^*)$, где $x^*$ — точка минимума исходной функции, определяемая как $Ax^* = b$. При этом $x = Q\hat{x} + x^*$.
    $$
    \begin{split}
    \uncover<+->{ f(\hat{x}) &= \frac12  (Q\hat{x} + x^*)^\top  A (Q\hat{x} + x^*) - b^\top  (Q\hat{x} + x^*) \\}
    \uncover<+->{ &= \frac12 \hat{x}^T Q^TAQ\hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - b^T Q\hat{x} - b^T x^*\\}
    \uncover<+->{ &= \frac12 \hat{x}^T \Lambda \hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - (x^*)^T A^TQ\hat{x} - (x^*)^T A x^*\\}
    \uncover<+->{ &= \frac12 \hat{x}^T \Lambda \hat{x} - \frac12 (x^*)^T A x^*} \uncover<+->{\simeq \frac12 \hat{x}^T \Lambda \hat{x} }
    \end{split}
    $$

:::
::: {.column width="30%"}
![](coordinate_shift.pdf)
:::
::::

## Анализ сходимости

Теперь мы можем работать с функцией $f(x) = \frac12 x^T \Lambda x$ с $x^* = 0$ без ограничения общности (убрав крышку из $\hat{x}$)

:::: {.columns}
::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{x^{k+1} &= x^k - \alpha^k \nabla f(x^k)} 
\uncover<+->{= x^k - \alpha^k \Lambda x^k \\ } 
\uncover<+->{&= (I - \alpha^k \Lambda) x^k \\ }
\uncover<+->{ x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)}) \, x^k_{(i)} \quad \text{для $i$-й координаты} \\ }
\uncover<+->{  x^{k}_{(i)} &= (1 - \alpha \, \lambda_{(i)})^k \, x^0_{(i)} \quad \text{при постоянном шаге } \alpha^k = \alpha}
\end{split}
$$
\uncover<+->{
Используем постоянный шаг $\alpha^k = \alpha$. Условие сходимости:
$$
\rho(\alpha) = \max_{i} |1 - \alpha \lambda_{(i)}| < 1
$$

. . .

Помним, что $\lambda_{\min} = \mu > 0$, $\lambda_{\max} = L \geq \mu$.}

:::: {.columns}

::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{ |1 - \alpha \mu| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha \mu < 1 \\ }
\uncover<+->{ \alpha < \tfrac{2}{\mu} \quad & \quad \alpha\mu > 0}
\end{split}
$$
:::

::: {.column width="50%"}

$$
\begin{split}
\uncover<+->{ |1 - \alpha L| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha L < 1 \\ }
\uncover<+->{ \alpha < \tfrac{2}{L} \quad & \quad \alpha L > 0}
\end{split}
$$
:::
::::

:::

. . .

::: {.column width="50%"}
Выберем $\alpha$, минимизирующий худший знаменатель прогрессии
$$
\begin{split}
\uncover<+->{ \rho^* &=  \min_{\alpha} \rho(\alpha) } \uncover<+->{  = \min_{\alpha} \max_{i} |1 - \alpha \lambda_{(i)}| \\ }
\uncover<+->{ &=  \min_{\alpha} \max \left\{|1 - \alpha \mu|, |1 - \alpha L| \right\} \\ }
\uncover<+->{ \alpha^* &: \quad  1 - \alpha^* \mu = \alpha^* L - 1 \\ }
\uncover<+->{ & \alpha^* = \frac{2}{\mu + L} } \uncover<+->{ \quad \rho^* = \frac{L - \mu}{L + \mu} \\ }
\uncover<+->{ |x^{k}_{(i)}| &\leq \left( \frac{L - \mu}{L + \mu} \right)^k |x^0_{(i)}| \\}
\uncover<+->{ \|x^{k}\|_2 &\leq \left( \frac{L - \mu}{L + \mu} \right)^k \|x^0\|_2 } \uncover<+->{ \quad f(x^{k}) \leq \left( \frac{L - \mu}{L + \mu} \right)^{2k} f(x^0)}
\end{split}
$$
:::
::::

## Анализ сходимости

Таким образом, имеем линейную сходимость по аргументу со скоростью $\frac{\varkappa - 1}{\varkappa + 1} = 1 - \frac{2}{\varkappa + 1}$, где $\varkappa = \frac{L}{\mu}$ — *число обусловленности* квадратичной задачи.

| $\varkappa$ | $\rho$ | Итераций до уменьшения ошибки по аргументу в $10$ раз | Итераций до уменьшения ошибки по функции в $10$ раз |
|:-:|:-:|:-----------:|:-----------:|
| $1.1$ | $0.05$ | $1$ | $1$ |
| $2$ | $0.33$ | $3$ | $2$ |
| $5$ | $0.67$ | $6$ | $3$ |
| $10$ | $0.82$ | $12$ | $6$ |
| $50$ | $0.96$ | $58$ | $29$ |
| $100$ | $0.98$ | $116$ | $58$ |
| $500$ | $0.996$ | $576$ | $288$ |
| $1000$ | $0.998$ | $1152$ | $576$ |

## Число обусловленности $\varkappa$

[![](condition_number_gd.pdf)](https://fmin.xyz/docs/visualizations/condition_number_gd.mp4)

# Случай PL-функций

## PL-функции. Линейная сходимость градиентного спуска без выпуклости

Говорят, что $f$ удовлетворяет условию Поляка-Лоясиевича (PL), если для некоторого $\mu > 0$ выполняется
$$
\Vert \nabla f(x) \Vert^2 \geq 2 \mu (f(x) - f^*) \quad \forall x
$$
Интересно, что градиентный спуск может сходиться линейно даже без выпуклости.

Следующие функции удовлетворяют условию PL, но не являются выпуклыми. [\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/PL_function.ipynb)

:::: {.columns}

::: {.column width="50%"}

$$
f(x) = x^2 + 3\sin^2(x)
$$

![PL-функция](pl_2d.pdf){width=67%}

:::

. . .

::: {.column width="50%"}

$$
f(x,y) = \dfrac{(y - \sin x)^2}{2}
$$

![PL-функция](pl_3d.pdf){width=84%}

:::
::::

## Анализ сходимости

:::{.callout-theorem}
Рассмотрим задачу
$$
\min_{x \in \mathbb{R}^d} f(x)
$$
и предположим, что $f$ является PL-функцией с константой $\mu$ и $L$-гладкой, для некоторых $L\geq \mu > 0$.

Рассмотрим последовательность $(x^k)_{k \in \mathbb{N}}$, сгенерированную методом градиентного спуска из точки $x^0$ с постоянным шагом $\alpha$, удовлетворяющим $0<\alpha \leq \frac{1}{L}$. Пусть $f^* = \min\limits_{x \in \mathbb{R}^d} f(x)$. Тогда:
$$
f(x^{k})-f^* \leq (1-\alpha \mu)^k (f(x^0)-f^*).
$$
:::
\pause
:::{.callout-theorem}
Если функция $f(x)$ дифференцируема и $\mu$-сильно выпукла, то она является PL-функцией.
:::


## Анализ сходимости

Используем $L$-гладкость вместе с правилом обновления, чтобы записать:
$$
\begin{split}
\uncover<+->{ f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\ }
\uncover<+->{ &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\ }
\uncover<+->{ &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\ }
\uncover<+->{ & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2,}
\end{split}
$$

. . .

где в последнем неравенстве использована гипотеза о шаге $\alpha L \leq 1$.

. . .

Теперь используем свойство PL-функции и получаем:
$$
f(x^{k+1}) \leq f(x^{k}) - \alpha \mu (f(x^{k}) - f^*).
$$
Вычтя $f^*$ из обеих частей этого неравенства и применив рекурсию, мы получим искомый результат.

# Выпуклый гладкий случай

## Выпуклый гладкий случай

:::{.callout-theorem}
Рассмотрим задачу
$$
\min_{x \in \mathbb{R}^d} f(x)
$$
Пусть $x^* = \arg\min\limits_{x \in \mathbb{R}^d} f(x)$, а $f^* = f(x^*)$. Предположим, что $f: \mathbb{R}^{d} \to \mathbb{R}$ является выпуклой и $L$-гладкой функцией, для некоторого $L>0$. Пусть $(x_{k})_{k \in \mathbb{N}}$ — последовательность итераций, сгенерированная методом градиентного спуска из точки $x_0$ с постоянным шагом $\alpha$, удовлетворяющим $0 < \alpha\leq \frac{1}{L}$. 

Тогда для всех 
$k \in \mathbb{N}$ справедливо:
$$
f(x_{k})-f^* \leq \frac{\|x_0-x^*\| ^2}{2 \alpha k}.
$$
:::

<!-- ## Анализ сходимости

* Как и раньше, сначала используем гладкость:
    $$
    \begin{split}
    \uncover<+->{ f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\ }
    \uncover<+->{ &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\ }
    \uncover<+->{ &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\ }
    \uncover<+->{ & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2, \\ }
    \uncover<+->{ f(x^{k}) - f(x^{k+1}) & \geq \dfrac{1}{2L} \Vert \nabla f(x^{k})\Vert^2 \quad \text{если } \alpha = \tfrac1L }
    \end{split}
    $$ {#eq-gd-cs-smoothness}

    . . .

    Обычно для сходящегося градиентного спуска чем больше допустимый шаг, тем быстрее сходимость, поэтому часто берут $\alpha = \tfrac1L$.
 * После этого используем выпуклость:
    $$
    \begin{split}
    \uncover<+->{ f(y) &\geq f(x) + \langle \nabla f(x), y-x\rangle} \uncover<+->{ \text{ где } y = x^*, x = x^k} \\
    \uncover<+->{f(x^k) - f^* &\leq \langle \nabla f(x^k), x^k-x^*\rangle }
    \end{split}
    $$ {#eq-gd-cs-convexity}

## Анализ сходимости

* Теперь подставляем (-@eq-gd-cs-convexity) в (-@eq-gd-cs-smoothness):
    $$
    \begin{split}
    \uncover<+->{ f(x^{k+1}) &\leq f(x^{k}) -\frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \leq f^* + \langle \nabla f(x^k), x^k-x^*\rangle - \frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \\ }
    \uncover<+->{ &= f^* + \langle \nabla f(x^k), x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\rangle \\ }
    \uncover<+->{ &= f^* + \frac{1}{2 \alpha}\left\langle \alpha \nabla f(x^k), 2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)\right\rangle }
    \end{split}
    $$
    \uncover<+->{ Пусть $a = x^k-x^*$ и $b = x^k-x^* - \alpha\nabla f(x^k)$.} \uncover<+->{Тогда $a+b = \alpha \nabla f(x^k)$ и $a-b=2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)$.}
    $$
    \begin{split}
    \uncover<+->{ f(x^{k+1}) &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^k-x^* - \alpha\nabla f(x^k)\|_2^2\right] \\ }
    \uncover<+->{ &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2\right] \\ }
    \uncover<+->{ 2\alpha \left(f(x^{k+1}) - f^*\right) &\leq \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2 }
    \end{split}
    $$
* Просуммируем по $i = 0,\dots, k-1$. Большинство слагаемых обнуляется из-за телескопической суммы:
    $$
    \begin{split}
    \uncover<+->{2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right) &\leq \|x^0-x^*\|_2^2 - \|x^{k}-x^*\|_2^2} \uncover<+->{ \leq \|x^0-x^*\|_2^2 }
    \end{split}
    $$ {#eq-gd-sc-telescopic}

## Анализ сходимости

* Поскольку на каждой итерации $f(x^{i+1}) \leq f(x^i)$, то
    $$
    kf(x^k) \leq \sum\limits_{i=0}^{k-1}f(x^{i+1})
    $$
* Теперь подставим это в (-@eq-gd-sc-telescopic):
    $$
    \begin{split}
    \uncover<+->{ 2\alpha kf(x^k) - 2\alpha kf^* &\leq 2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right)  \leq \|x^0-x^*\|_2^2 \\ }
    \uncover<+->{ f(x^k) - f^* &\leq \frac{\|x^0-x^*\|_2^2}{2 \alpha k} } \uncover<+->{ \leq  \frac{L \|x^0-x^*\|_2^2}{2 k} }
    \end{split}
    $$
 -->


## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} ,\ \mu = 0,\ L = 100.
$$

![](gd_random_0.001_100_60.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} , \ \mu = 10,\ L = 110.
$$

![](gd_random_10_100_60.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} , \ \mu = 10,\ L = 1000.
$$

![](gd_random_10_1000_60.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} , \ \mu = 10,\ L = 1000.
$$

![](gd_clustered_10_1000_60.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} , \ \mu = 10,\ L = 1000.
$$

![](gd_clustered_10_1000_600.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\} , \ \mu = 10,\ L = 1000.
$$

![]("gd_uniform spectrum_1_100_60.pdf")

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{f(x) = \frac{1}{2} x^T A x - b^T x \right\}
$$

![](gd_Hilbert_1_10_60.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{ f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \right\}
$$

![]("GD 0.07GD 0.9GD 10.0_0.pdf"){fig-align="center" width=95%}

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{ f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \right\}
$$

![]("GD 0.12GD 0.14GD 0.15_0.1.pdf"){fig-align="center" width=95%}


## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{ f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \right\}
$$

![](gd_non_linear_1000_300_0_None.pdf)

## Численные эксперименты

$$
\min_{x \in \mathbb{R}^n} \left\{ f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \right\}
$$

![](gd_non_linear_1000_300_1_None.pdf)

## Сходимость градиентного спуска

$$
\text{Градиентный спуск:} \qquad \qquad \min_{x \in \mathbb{R}^n} f(x) \qquad \qquad x_{k+1} = x_k - \alpha_k \nabla f(x_k)
$$

|выпуклая (негладкая) | гладкая (невыпуклая) | гладкая & выпуклая | гладкая & сильно выпуклая |
|:------:|:-------:|:------:|:--------:|
| $f(x_k) - f^* =  \mathcal{O} \left( \tfrac{1}{\sqrt{k}} \right)$ | $\min\limits_{0 \leq i \leq k}\|\nabla f(x_i)\| = \mathcal{O} \left( \tfrac{1}{\sqrt{k}} \right)$ | $f(x_k) - f^* =  \mathcal{O} \left( \tfrac{1}{k} \right)$ | $\|x_k - x^*\|^2 = \mathcal{O} \left( \left(1 - \tfrac{\mu}{L}\right)^k \right)$ |
| $k_\varepsilon =  \mathcal{O} \left( \tfrac{1}{\varepsilon^2} \right)$ | $k_\varepsilon = \mathcal{O} \left( \tfrac{1}{\varepsilon^2} \right)$ | $k_\varepsilon =  \mathcal{O}  \left( \tfrac{1}{\varepsilon} \right)$ | $k_\varepsilon  = \mathcal{O} \left( \varkappa \log \tfrac{1}{\varepsilon}\right)$ |

\pause
:::: {.columns}

::: {.column width="50%"}
Для гладкой сильно выпуклой функции мы имеем:
$$
f(x_{k})-f^* \leq \left(1- \dfrac{\mu}{L}\right)^k (f(x_0)-f^*).
$$

. . .

Обратите внимание, что для любого $x$, поскольку $e^{-x}$ выпуклая и $1-x$ является её касательной в точке $x=0$, мы имеем:
$$
1 - x \leq e^{-x}
$$
:::

. . .

::: {.column width="50%"}
Наконец:
$$
\begin{aligned}
\uncover<+->{\varepsilon &= f(x_{k_\varepsilon})-f^* }\uncover<+->{\leq  \left(1- \dfrac{\mu}{L}\right)^{k_\varepsilon} (f(x_0)-f^*) \\}
\uncover<+->{&\leq \exp\left(- k_\varepsilon\dfrac{\mu}{L}\right) (f(x_0)-f^*) \\}
\uncover<+->{k_\varepsilon &\geq \varkappa \log \dfrac{f(x_0)-f^*}{\varepsilon} = \mathcal{O} \left( \varkappa \log \dfrac{1}{\varepsilon}\right)}
\end{aligned}
$$
:::

::::

## Сходимость градиентного спуска

\uncover<+->{{\bf Вопрос:} Можно ли добиться лучшей скорости сходимости, используя только информацию первого порядка? }\uncover<+->{{\bf Да, можно.}}

## Нижние оценки

* Как правило, это гораздо более нетривиальные результаты - они показывают, что никакой метод не может сходиться быстрее, чем нижняя оценка на выбранном классе функций. 
* Часто, эти результаты получаются путём предъявления конкретной функции из класса, для которой никакой метод не может сходиться быстрее, чем нижняя оценка.
* Для нижних оценок пишут $\Omega \left( \cdot \right)$ вместо $\mathcal{O} \left( \cdot \right)$.
\pause

| выпуклая (негладкая) | гладкая (невыпуклая)^[[Carmon, Duchi, Hinder, Sidford, 2017](https://arxiv.org/pdf/1710.11606.pdf)] | гладкая & выпуклая^[[Nemirovski, Yudin, 1979](https://fmin.xyz/assets/files/nemyud1979.pdf)] | гладкая & сильно выпуклая |
|:------:|:-------:|:------:|:--------:|
| $f(x_k) - f^* =  \Omega \left( \tfrac{1}{\sqrt{k}} \right)$ | $\min\limits_{0 \leq i \leq k}\|\nabla f(x_i)\| = \Omega \left( \tfrac{1}{\sqrt{k}} \right)$ | $f(x_k)-f^*=\Omega\!\left(\tfrac{1}{k^2}\right)$ | $f(x_k)-f^*=\Omega\!\left(\left(\tfrac{\sqrt{\varkappa}-1}{\sqrt{\varkappa}+1}\right)^{\!2k}\right)$ |
| $k_\varepsilon =  \Omega \left( \tfrac{1}{\varepsilon^2} \right)$ | $k_\varepsilon=\Omega\!\left(\tfrac{1}{\varepsilon^2}\right)$ | $k_\varepsilon=\Omega\!\left(\tfrac{1}{\sqrt{\varepsilon}}\right)$ | $k_\varepsilon=\Omega\!\big(\sqrt{\varkappa}\,\log\tfrac{1}{\varepsilon}\big)$ |

\pause
Например, из таблицы выше следует, что никакой метод первого порядка определённой формы не может сходиться быстрее, чем $\Omega \left( \tfrac{1}{k^2} \right)$ ($\Omega \left( \tfrac{1}{\sqrt{\varepsilon}} \right)$ для гладкой выпуклой функции) для гладкой выпуклой функции.

# Бонус: доказательства сходимости

## Любая $\mu$-сильно выпуклая дифференцируемая функция является PL-функцией

:::{.callout-theorem}
Если функция $f(x)$ дифференцируема и $\mu$-сильно выпукла, то она является PL-функцией.
:::

**Доказательство**

:::: {.columns}

::: {.column width="60%"}

По критерию сильной выпуклости первого порядка:
$$
f(y) \geq f(x) + \nabla f(x)^T(y-x) + \tfrac{\mu}{2}\|y-x\|_2^2
$$
Положим $y = x^*$:
$$
\begin{split}
\uncover<+->{ f(x^*) &\geq f(x) + \nabla f(x)^T(x^*-x) + \tfrac{\mu}{2}\|x^*-x\|_2^2 \\ }
\uncover<+->{ f(x) - f(x^*) &\leq \nabla f(x)^T(x-x^*) - \tfrac{\mu}{2}\|x^*-x\|_2^2 = \\ }
\uncover<+->{ &= \left(\nabla f(x) - \tfrac{\mu}{2}(x^*-x)\right)^T (x-x^*) = \\ }
\uncover<+->{ &= \frac12 \left(\tfrac{2}{\sqrt{\mu}}\nabla f(x) - \sqrt{\mu}(x^*-x)\right)^T \sqrt{\mu}(x-x^*)\\ }
\end{split}
$$
:::

. . .

::: {.column width="40%"}

Пусть $a = \frac{1}{\sqrt{\mu}}\nabla f(x)$ и $b =\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)$ 

. . .

Тогда $a+b = \sqrt{\mu}(x-x^*)$ и $a-b=\frac{2}{\sqrt{\mu}}\nabla f(x)-\sqrt{\mu}(x-x^*)$
:::
::::

## Любая $\mu$-сильно выпуклая дифференцируемая функция является PL-функцией
$$
\begin{split}
\uncover<+->{ f(x) - f(x^*) &\leq \frac12 \left(\frac{1}{\mu}\|\nabla f(x)\|^2_2 - \left\|\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)\right\|_2^2\right) \\ }
\uncover<+->{ f(x) - f(x^*) &\leq \frac{1}{2\mu}\|\nabla f(x)\|^2_2, \\ }
\end{split}
$$

. . .

которое является точным условием PL. Это означает, что мы уже имеем доказательство линейной сходимости для любой сильно выпуклой функции.


## Сходимость градиентного спуска в выпуклом гладком случае [1/4]

:::{.callout-theorem}
Рассмотрим задачу
$$
\min_{x \in \mathbb{R}^d} f(x)
$$
Пусть $f^* = \min\limits_{x \in \mathbb{R}^d} f(x)$. Предположим, что $f: \mathbb{R}^{d} \to \mathbb{R}$ является выпуклой и $L$-гладкой функцией, для некоторого $L>0$. Пусть $(x_{k})_{k \in \mathbb{N}}$ — последовательность итераций, сгенерированная методом градиентного спуска из точки $x_0$ с постоянным шагом $\alpha$, удовлетворяющим $0 < \alpha\leq \frac{1}{L}$. 

Тогда для всех 
$k \in \mathbb{N}$ справедливо:
$$
f(x_{k})-f^* \leq \frac{\|x_0-x^*\| ^2}{2 \alpha k}.
$$
:::

\uncover<+->{\textbf{Заметим}, что мы здесь никак не упоминаем точку минимума. То есть, это сходимость $\forall x \in \mathbb{R}^d$ (в том числе и до точки минимума).}

## Сходимость градиентного спуска в выпуклом гладком случае [2/4]

Наш инструментарий:

1. Выпуклость: 
    $$
        f(x) \ge f(y) + \left\langle \nabla f(y), x - y \right\rangle,\ \forall x, y.
    $$ {#eq-gd-cs-convexity}

2. Гладкость:
    $$
        f(x) \le f(y) + \left\langle \nabla f(y), x - y \right\rangle + \frac{L}{2} \left\| x - y \right\|^{2},\ \forall x, y.
    $$ {#eq-gd-cs-smoothness}

3. 3-point identity (по сути, квадрат разности):
    $$
        \|a - b\|^2 = \|a - c - (b - c)\|^2 = \|a - c\|^2 - 2 \langle a - c, b - c \rangle + \|b - c\|^2
    $$
    переносим справа все кроме $\|b - c\|^2$ налево и меняем местами все факторы внутри каждого из перенесенных членов:
    $$
        \|b - c\|^2 = \|b - a\|^2 + 2 \langle c - a, c - b \rangle - \|c - a\|^2.
    $$ {#eq-gd-cs-three-point}

* Подставляем в (-@eq-gd-cs-three-point) $b \equiv x$, $c \equiv x_{k + 1}$, $a \equiv x_k$ и домножаем все на $\frac{1}{2}$:
    $$
        \begin{split}
            \uncover<+->{\frac{1}{2} \|x - x_{k + 1}\|^2 &= \frac{1}{2} \left\| x - x_k \right\|^{2} + \left\langle x_{k + 1} - x_k, x_{k + 1} - x \right\rangle - \frac{1}{2} \left\| x_{k + 1} - x_k \right\|^2\\ }
            \uncover<+->{ &= \frac{1}{2} \left\| x - x_k \right\|^{2} - \alpha \left\langle \nabla f(x_k) , x_{k + 1} - x \right\rangle - \frac{1}{2} \left\| x_{k + 1} - x_k \right\|^{2}.}
        \end{split}
    $$ {#eq-gd-cs-first}


## Сходимость градиентного спуска в выпуклом гладком случае [3/4]

* Посмотрим внимательнее на скалярное произведение $- \alpha\left\langle \nabla f(x_k), x_{k + 1} - x \right\rangle$ и воспользуемся сначала выпуклостью (-@eq-gd-cs-convexity), а потом -- гладкостью (-@eq-gd-cs-smoothness):
$$
    \begin{split}
        \uncover<+->{- \alpha\left\langle \nabla f(x_k), x_{k + 1} - x \right\rangle &= \alpha \left( \left\langle \nabla f(x_k), x - x_k \right\rangle + \left\langle \nabla f(x_k), x_k - x_{k + 1} \right\rangle \right)\\ }
        \uncover<+->{&\overset{\eqref{eq-gd-cs-convexity}}{\le} \alpha \left( f(x) - f(x_k) + \left\langle \nabla f(x_k), x_k - x_{k + 1} \right\rangle \right) \\ }
        \uncover<+->{&\overset{\eqref{eq-gd-cs-smoothness}}{\le} \alpha \left( f(x) - f(x_{k + 1}) + \frac{L}{2} \left\| x_{k + 1} - x_k \right\|^{2} \right),}
    \end{split}
$$

* Подставляем это все обратно в \eqref{eq-gd-cs-first} и используем условие на размер шага $\alpha \le \frac{1}{L}$:
$$
    \begin{gathered}
        \uncover<+->{\frac{1}{2} \left\| x - x_{k + 1} \right\|^{2} \le \frac{1}{2} \left\| x - x_k \right\|^{2} + \alpha \left( f(x) - f(x_{k + 1}) \right)  + \left( \frac{\alpha L}{2} - \frac{1}{2} \right) \left\| x_{k + 1} - x_k \right\|^{2}}
    \end{gathered}
$$
$$
    \begin{aligned}
        \uncover<+->{\frac{1}{2} \left\| x - x_{k + 1} \right\|^{2} - \frac{1}{2} \left\| x - x_k \right\|^{2} 
            &\le  \alpha \left( f(x) - f(x_{k + 1}) \right)  + \left( \frac{\alpha L}{2} - \frac{1}{2} \right) \left\| x_{k + 1} - x_k \right\|^{2} \\ } 
        \uncover<+->{&\overset{(\alpha \le 1/L)}{\le} \frac{1}{L} \left( f(x) - f(x_{k + 1}) \right).}
    \end{aligned}
$$

* Переносим правую часть влево, левую - вправо и домножаем на $L$:
$$
\uncover<+->{f(x_{k + 1} - f(x)) \le \frac{L}{2} \left( \left\| x - x_k \right\|^{2} - \left\| x - x_{k + 1} \right\|^{2} \right)}.
$$

## Сходимость градиентного спуска в выпуклом гладком случае [4/4]

* Берем среднее от левой и правой частей от по всем $k$ от 0 до $N-1$:
$$
    \begin{aligned}
        \uncover<+->{\frac{1}{N} \sum_{k = 0}^{N - 1} \left( f(x_{k + 1}) - f(x) \right) &\le \frac{L}{2N} \sum_{k=0}^{N-1} \left( \left\| x - x_k \right\|^{2} - \left\| x - x_{k + 1} \right\| \right) \\ }
        \uncover<+->{&= \frac{L}{2N} \left( \left\| x - x_0 \right\|^{2} - \left\| x - x_{k + 1} \right\|^{2} \right) \\ }
        \uncover<+->{&\le \frac{L}{2N} \left\| x - x_0 \right\|^{2}.}
    \end{aligned}
$$ {#eq-gd-cs-second}

* Так как для выпуклых функций \eqref{eq-gd-cs-convexity} градиентный спуск монотонен:
$$
    \begin{aligned}
        f(x_k) &\ge f(x_{k + 1}) + \left\langle \nabla f(x_{k + 1}), x_k - x_{k + 1} \right\rangle \\
        &= f(x_{k + 1}) + \alpha \left\| \nabla f(x_{k + 1}) \right\|^{2} \\
        &\ge f(x_{k + 1}),
    \end{aligned}
$$
\uncover<+->{ то $\frac{1}{N} \sum_{i = 0}^{N-1} \left( f(x_{k + 1}) - f(x) \right) \ge \min_{i = 0,... , N - 1} f(x_{i + 1}) - f(x) = f(x_{N}) - f(x)$. } 
\uncover<+->{Подставляя это в \eqref{eq-gd-cs-second}, получаем искомый результат.}