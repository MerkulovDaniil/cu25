---
title: "Градиентный спуск. Теоремы сходимости в гладком случае (выпуклые, сильно выпуклые, PL). Верхние и нижние оценки сходимости."
author: Даня Меркулов
institute: Оптимизация для всех! ЦУ
format: 
    beamer:
        pdf-engine: xelatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: true
        incremental: true
        include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
header-includes:
 - \newcommand{\bgimage}{../files/back8.jpeg}
---

# Градиентный спуск

## Направление локального наискорейшего спуска

:::: {.columns}

::: {.column width="40%"}
Рассмотрим линейное приближение дифференцируемой функции $f$ вдоль некоторого направления $h, \|h\|_2 = 1$:

. . .

$$
f(x + \alpha h) = f(x) + \alpha \langle f'(x), h \rangle + o(\alpha)
$$

. . .

Мы хотим, чтобы $h$ было убывающим направлением:
$$
f(x + \alpha h) < f(x)
$$
$$
f(x) + \alpha \langle f'(x), h \rangle + o(\alpha) < f(x)
$$

. . .

и переходя к пределу при $\alpha \rightarrow 0$:
$$
\langle f'(x), h \rangle \leq 0
$$
:::

. . .

::: {.column width="60%"}

Также из неравенства Коши-Буняковского:
$$
\begin{split}
|\langle f'(x), h \rangle | &\leq \| f'(x) \|_2 \| h \|_2 \\
\langle f'(x), h \rangle &\geq -\| f'(x) \|_2 \| h \|_2 = -\| f'(x) \|_2
\end{split}
$$

. . .

Таким образом, направление антиградиента
$$
h = -\dfrac{f'(x)}{\|f'(x)\|_2}
$$
даёт направление **наискорейшего локального** убывания функции $f$.

. . .

Итерация метода имеет вид:
$$
x_{k+1} = x_k - \alpha f'(x_k)
$$

:::
::::

## Дифференциальное уравнение градиентного потока

:::: {.columns}
::: {.column width="78%"}

Рассмотрим следующее дифференциальное уравнение, которое называется уравнением градиентного потока.
$$
\tag{ГП}
\frac{dx}{dt} = -f'(x(t))
$$

. . .

 и дискретизируем его на равномерной сетке с шагом $\alpha$:
$$
\frac{x_{k+1} - x_k}{\alpha} = -f'(x_k),
$$

. . .

где $x_k \equiv x(t_k)$ и $\alpha = t_{k+1} - t_k$ - шаг сетки.

Отсюда мы получаем выражение для $x_{k+1}$
$$
x_{k+1} = x_k - \alpha f'(x_k),
$$
которое является градиентным спуском.

[Открыть в Colab $\clubsuit$](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/GD_vs_GF.ipynb)
:::

. . .

::: {.column width="22%"}
![Траектория градиентного потока](GD_vs_GF.pdf)
:::
::::

## Сходимость алгоритма градиентного спуска

Существенно зависит от выбора шага $\alpha$:

[![](gd_2d.png)](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/GD_2d_visualization.ipynb)

## Точный линейный поиск aka метод наискорейший спуска

:::: {.columns}
::: {.column width="80%"}
$$
\alpha_k = \text{arg}\min_{\alpha \in \mathbb{R^+}} f(x_{k+1}) = \text{arg}\min_{\alpha \in \mathbb{R^+}} f(x_k - \alpha \nabla f(x_k))
$$
Более теоретический, чем практический подход. Он также позволяет анализировать сходимость, но часто точный линейный поиск может быть сложным, если вычисление функции занимает слишком много времени или стоит слишком дорого.

Интересное теоретическое свойство этого метода заключается в том, что каждая следующая итерация ортогональна предыдущей:
$$
\alpha_k = \text{arg}\min_{\alpha \in \mathbb{R^+}} f(x_k - \alpha \nabla f(x_k))
$$

. . .

Оптимальные условия:

. . .

$$
\nabla f(x_{k+1})^\top \nabla f(x_k) = 0
$$

:::
::: {.column width="20%"}

![Наискорейший спуск](GD_vs_Steepest.pdf)

[Открыть в Colab $\clubsuit$](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/Steepest_descent.ipynb)
:::
::::

# Сильно выпуклые квадратичные функции

## Сдвиг координат

:::: {.columns}

::: {.column width="70%"}

Рассмотрим следующую задачу квадратичной оптимизации:
$$
\label{problem}
\min\limits_{x \in \mathbb{R}^d} f(x) =  \min\limits_{x \in \mathbb{R}^d} \dfrac{1}{2} x^\top  A x - b^\top  x + c, \text{ where }A \in \mathbb{S}^d_{++}.
$$

. . .

* Во-первых, без ограничения общности мы можем установить $c = 0$, что не повлияет на процесс оптимизации.
* Во-вторых, у нас есть спектральное разложение матрицы $A = Q \Lambda Q^T$.
* Давайте покажем, что мы можем сделать сдвиг координат, чтобы сделать анализ немного проще. Пусть $\hat{x} = Q^T(x - x^*)$, где $x^*$ - точка минимума исходной функции, определяемая как $Ax^* = b$. При этом $x = Q\hat{x} + x^*$.
    $$
    \begin{split}
    \uncover<+->{ f(\hat{x}) &= \frac12  (Q\hat{x} + x^*)^\top  A (Q\hat{x} + x^*) - b^\top  (Q\hat{x} + x^*) \\}
    \uncover<+->{ &= \frac12 \hat{x}^T Q^TAQ\hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - b^T Q\hat{x} - b^T x^*\\}
    \uncover<+->{ &= \frac12 \hat{x}^T \Lambda \hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - (x^*)^T A^TQ\hat{x} - (x^*)^T A x^*\\}
    \uncover<+->{ &= \frac12 \hat{x}^T \Lambda \hat{x} - \frac12 (x^*)^T A x^*} \uncover<+->{\simeq \frac12 \hat{x}^T \Lambda \hat{x} }
    \end{split}
    $$

:::
::: {.column width="30%"}
![](coordinate_shift.pdf)
:::
::::

## Анализ сходимости

Теперь мы можем работать с функцией $f(x) = \frac12 x^T \Lambda x$ с $x^* = 0$ без ограничения общности (убрав шляпу из $\hat{x}$)

:::: {.columns}
::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{x^{k+1} &= x^k - \alpha^k \nabla f(x^k)} 
\uncover<+->{= x^k - \alpha^k \Lambda x^k \\ } 
\uncover<+->{&= (I - \alpha^k \Lambda) x^k \\ }
\uncover<+->{ x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)}) x^k_{(i)} \text{ Для $i$-ой координаты} \\ }
\uncover<+->{  x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)})^k x^0_{(i)}}
\end{split}
$$
\uncover<+->{
Используем постоянный шаг $\alpha^k = \alpha$. Условие сходимости:
$$
\rho(\alpha) = \max_{i} |1 - \alpha \lambda_{(i)}| < 1
$$
Помним, что $\lambda_{\text{min}} = \mu > 0, \lambda_{\text{max}} = L \geq \mu$.}

:::: {.columns}

::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{ |1 - \alpha \mu| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha \mu < 1 \\ }
\uncover<+->{ \alpha < \frac{2}{\mu} \quad & \quad \alpha\mu > 0}
\end{split}
$$
:::

::: {.column width="50%"}

$$
\begin{split}
\uncover<+->{ |1 - \alpha L| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha L < 1 \\ }
\uncover<+->{ \alpha < \frac{2}{L} \quad & \quad \alpha L > 0}
\end{split}
$$
:::
::::

:::

. . .

::: {.column width="50%"}
Теперь мы хотим настроить $\alpha$, чтобы выбрать лучшую (наименьшую) скорость сходимости

$$
\begin{split}
\uncover<+->{ \rho^* &=  \min_{\alpha} \rho(\alpha) } \uncover<+->{  = \min_{\alpha} \max_{i} |1 - \alpha \lambda_{(i)}| \\ }
\uncover<+->{ &=  \min_{\alpha} \left\{|1 - \alpha \mu|, |1 - \alpha L| \right\} \\ }
\uncover<+->{ \alpha^* &: \quad  1 - \alpha^* \mu = \alpha^* L - 1 \\ }
\uncover<+->{ & \alpha^* = \frac{2}{\mu + L} } \uncover<+->{ \quad \rho^* = \frac{L - \mu}{L + \mu} \\ }
\uncover<+->{ x^{k+1}_{(i)} &= \left( \frac{L - \mu}{L + \mu} \right)^k x^0_{(i)} \\}
\uncover<+->{ \|x^{k+1}\|_2 &\leq \left( \frac{L - \mu}{L + \mu} \right)^k \|x^0\|_2 } \uncover<+->{ \quad f(x^{k+1}) \leq \left( \frac{L - \mu}{L + \mu} \right)^{2k} f(x^0)}
\end{split}
$$
:::
::::

## Анализ сходимости

Таким образом, мы имеем линейную сходимость в области с коэффициентом $\frac{\varkappa - 1}{\varkappa + 1} = 1 - \frac{2}{\varkappa + 1}$, где $\varkappa = \frac{L}{\mu}$ иногда называется *числом обусловленности* квадратичной задачи.

| $\varkappa$ | $\rho$ | Итераций для уменьшения разрыва области в $10$ раз | Итераций для уменьшения разрыва в функции в $10$ раз |
|:-:|:-:|:-----------:|:-----------:|
| $1.1$ | $0.05$ | $1$ | $1$ |
| $2$ | $0.33$ | $3$ | $2$ |
| $5$ | $0.67$ | $6$ | $3$ |
| $10$ | $0.82$ | $12$ | $6$ |
| $50$ | $0.96$ | $58$ | $29$ |
| $100$ | $0.98$ | $116$ | $58$ |
| $500$ | $0.996$ | $576$ | $288$ |
| $1000$ | $0.998$ | $1152$ | $576$ |

## Число обусловленности $\varkappa$

[![](condition_number_gd.pdf)](https://fmin.xyz/docs/visualizations/condition_number_gd.mp4)

# Случай PL-функции

## Условие PL-функции. Линейная сходимость градиентного спуска без выпуклости

Неравенство PL выполняется, если выполняется следующее условие для некоторого $\mu > 0$,
$$
\Vert \nabla f(x) \Vert^2 \geq 2 \mu (f(x) - f^*) \quad \forall x
$$
Интересно, что градиентный спуск может сходиться линейно даже без выпуклости.

Следующие функции удовлетворяют условию PL, но не являются выпуклыми. [\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/PL_function.ipynb)

:::: {.columns}

::: {.column width="50%"}

$$
f(x) = x^2 + 3\sin^2(x)
$$

![PL-функция](pl_2d.pdf){width=65%}

:::

. . .

::: {.column width="50%"}

$$
f(x,y) = \dfrac{(y - \sin x)^2}{2}
$$

![PL-функция](pl_3d.pdf){width=80%}

:::
::::

## Анализ сходимости

:::{.callout-theorem}
Рассмотрим задачу
$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$
и предположим, что $f$ является $\mu$-PL-функцией и $L$-гладкой, для некоторого $L\geq \mu >0$.

Рассмотрим последовательность $(x^k)_{k \in \mathbb{N}}$, сгенерированную алгоритмом градиентного спуска с постоянным шагом $\alpha$, удовлетворяющим $0<\alpha \leq \frac{1}{L}$. Тогда:
$$
f(x^{k})-f^* \leq (1-\alpha \mu)^k (f(x^0)-f^*).
$$
:::

## Анализ сходимости

Мы можем использовать $L$-гладкость, вместе с правилом обновления, чтобы записать:
$$
\begin{split}
\uncover<+->{ f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\ }
\uncover<+->{ &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\ }
\uncover<+->{ &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\ }
\uncover<+->{ & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2,}
\end{split}
$$

. . .

где в последнем неравенстве мы использовали нашу гипотезу о шаге, что $\alpha L \leq 1$.

. . .

Теперь мы можем использовать свойство PL-функции, чтобы записать:
$$
f(x^{k+1}) \leq f(x^{k}) - \alpha \mu (f(x^{k}) - f^*).
$$
Вычтя $f^*$ из обеих частей этого неравенства и применив рекурсию, мы получим искомый результат.

## Любая $\mu$-сильно выпуклая дифференцируемая функция является PL-функцией

:::{.callout-theorem}
Если функция $f(x)$ дифференцируема и $\mu$-сильно выпукла, то она является PL-функцией.
:::

**Доказательство**

:::: {.columns}

::: {.column width="60%"}

По критерию сильной выпуклости первого порядка:
$$
f(y) \geq f(x) + \nabla f(x)^T(y-x) + \dfrac{\mu}{2}\|y-x\|_2^2
$$
Положим $y = x^*$:
$$
\begin{split}
\uncover<+->{ f(x^*) &\geq f(x) + \nabla f(x)^T(x^*-x) + \dfrac{\mu}{2}\|x^*-x\|_2^2 \\ }
\uncover<+->{ f(x) - f(x^*) &\leq \nabla f(x)^T(x-x^*) - \dfrac{\mu}{2}\|x^*-x\|_2^2 = \\ }
\uncover<+->{ &= \left(\nabla f(x)^T - \dfrac{\mu}{2}(x^*-x)\right)^T (x-x^*) = \\ }
\uncover<+->{ &= \frac12 \left(\frac{2}{\sqrt{\mu}}\nabla f(x)^T - \sqrt{\mu}(x^*-x)\right)^T \sqrt{\mu}(x-x^*)\\ }
\end{split}
$$
:::

. . .

::: {.column width="40%"}

Пусть $a = \frac{1}{\sqrt{\mu}}\nabla f(x)$ и $b =\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)$ 

. . .

Тогда $a+b = \sqrt{\mu}(x-x^*)$ и $a-b=\frac{2}{\sqrt{\mu}}\nabla f(x)-\sqrt{\mu}(x-x^*)$
:::
::::

## Любая $\mu$-сильно выпуклая дифференцируемая функция является PL-функцией
$$
\begin{split}
\uncover<+->{ f(x) - f(x^*) &\leq \frac12 \left(\frac{1}{\mu}\|\nabla f(x)\|^2_2 - \left\|\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)\right\|_2^2\right) \\ }
\uncover<+->{ f(x) - f(x^*) &\leq \frac{1}{2\mu}\|\nabla f(x)\|^2_2, \\ }
\end{split}
$$

. . .

которое является точным условием PL. Это означает, что мы уже имеем доказательство линейной сходимости для любой сильно выпуклой функции.

# Выпуклый гладкий случай

## Выпуклый гладкий случай

:::{.callout-theorem}
Рассмотрим задачу
$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$
и предположим, что $f$ является выпуклой и $L$-гладкой, для некоторого $L>0$.

Пусть $(x^{k})_{k \in \mathbb{N}}$ - последовательность итераций, сгенерированная алгоритмом градиентного спуска с постоянным шагом $\alpha$, удовлетворяющим $0 < \alpha\leq \frac{1}{L}$. Тогда, для всех $x^* \in {\rm{argmin}}~f$, для всех $k \in \mathbb{N}$ мы имеем:
$$
f(x^{k})-f^* \leq \frac{\|x^0-x^*\| ^2}{2 \alpha k}.
$$
:::

## Анализ сходимости

* Как и раньше, мы сначала используем гладкость:
    $$
    \begin{split}
    f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\
    &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\
    &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\
    & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2, \\
    f(x^{k}) - f(x^{k+1}) & \geq \dfrac{1}{2L} \Vert \nabla f(x^{k})\Vert^2 \text{ if } \alpha = \frac1L
    \end{split}
    $$ {#eq-gd-cs-smoothness}
    Обычно для сходящегося алгоритма градиентного спуска чем больше шаг, тем быстрее сходимость. Поэтому мы часто будем использовать $\alpha = \frac1L$.
 * После этого мы используем выпуклость:
    $$
    \begin{split}
    \uncover<+->{ f(y) &\geq f(x) + \langle \nabla f(x), y-x\rangle} \uncover<+->{ \text{ with } y = x^*, x = x^k} \\
    \uncover<+->{f(x^k) - f^* &\leq \langle \nabla f(x^k), x^k-x^*\rangle }
    \end{split}
    $$ {#eq-gd-cs-convexity}

## Анализ сходимости

* Теперь мы подставляем @eq-gd-cs-convexity в @eq-gd-cs-smoothness:
    $$
    \begin{split}
    \uncover<+->{ f(x^{k+1}) &\leq f(x^{k}) -\frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \leq f^* + \langle \nabla f(x^k), x^k-x^*\rangle - \frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \\ }
    \uncover<+->{ &= f^* + \langle \nabla f(x^k), x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\rangle \\ }
    \uncover<+->{ &= f^* + \frac{1}{2 \alpha}\left\langle \alpha \nabla f(x^k), 2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)\right\rangle }
    \end{split}
    $$
    \uncover<+->{ Let $a = x^k-x^*$ and $b =x^k-x^* - \alpha\nabla f(x^k)$.} \uncover<+->{Then $a+b = \alpha \nabla f(x^k)$ and $a-b=2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)$.}
    $$
    \begin{split}
    \uncover<+->{ f(x^{k+1}) &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^k-x^* - \alpha\nabla f(x^k)\|_2^2\right] \\ }
    \uncover<+->{ &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2\right] \\ }
    \uncover<+->{ 2\alpha \left(f(x^{k+1}) - f^*\right) &\leq \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2 }
    \end{split}
    $$
* Теперь предположим, что последняя строка определена для некоторого индекса $i$ и просуммируем по $i \in [0, k-1]$. Большинство слагаемых будут обнулятся из-за телескопической суммы:
    $$
    \begin{split}
    \uncover<+->{2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right) &\leq \|x^0-x^*\|_2^2 - \|x^{k}-x^*\|_2^2} \uncover<+->{ \leq \|x^0-x^*\|_2^2 }
    \end{split}
    $$ {#eq-gd-sc-telescopic}

## Анализ сходимости

* Из-за монотонного убывания на каждой итерации $f(x^{i+1}) < f(x^i)$:
    $$
    kf(x^k) \leq \sum\limits_{i=0}^{k-1}f(x^{i+1})
    $$
* Теперь подставим это в @eq-gd-sc-telescopic:
    $$
    \begin{split}
    \uncover<+->{ 2\alpha kf(x^k) - 2\alpha kf^* &\leq 2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right)  \leq \|x^0-x^*\|_2^2 \\ }
    \uncover<+->{ f(x^k) - f^* &\leq \frac{\|x^0-x^*\|_2^2}{2 \alpha k} } \uncover<+->{ \leq  \frac{L \|x^0-x^*\|_2^2}{2 k} }
    \end{split}
    $$

## Итог

$$
\text{Градиентный спуск:} \qquad \qquad \min_{x \in \mathbb{R}^n} f(x) \qquad \qquad x^{k+1} = x^k - \alpha^k \nabla f(x^k)
$$

| гладкий (не выпуклый) | гладкий и выпуклый | гладкий и сильно выпуклый (или PL) |
|:-----:|:-----:|:--------:|
| $\|\nabla f(x^k)\|^2 \sim \mathcal{O} \left( \dfrac{1}{k} \right)$ | $f(x^k) - f^* \sim  \mathcal{O} \left( \dfrac{1}{k} \right)$ | $\|x^k - x^*\|^2 \sim \mathcal{O} \left( \left(1 - \dfrac{\mu}{L}\right)^k \right)$ |
| $k_\varepsilon \sim \mathcal{O} \left( \dfrac{1}{\varepsilon} \right)$ | $k_\varepsilon \sim  \mathcal{O}  \left( \dfrac{1}{\varepsilon} \right)$ | $k_\varepsilon  \sim \mathcal{O} \left( \varkappa \log \dfrac{1}{\varepsilon}\right)$ |

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_0.001_100_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_10_100_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_10_1000_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_clustered_10_1000_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_clustered_10_1000_600.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_uniform spectrum_1_100_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_Hilbert_1_10_60.pdf)

## Численные эксперименты

$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![]("GD 0.07GD 0.9GD 10.0_0.pdf"){fig-align="center" width=95%}

## Численные эксперименты

$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![]("GD 0.12GD 0.14GD 0.15_0.1.pdf"){fig-align="center" width=95%}


## Численные эксперименты

$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![](gd_non_linear_1000_300_0_None.pdf)

## Численные эксперименты

$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![](gd_non_linear_1000_300_1_None.pdf)