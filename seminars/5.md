---
title: Условия оптимальности. Ограничения равенства и неравенства. Условия ККТ.
author: Семинар
institute: Оптимизация для всех! ЦУ
format: 
   beamer:
      pdf-engine: xelatex
      aspectratio: 169
      fontsize: 9pt
      section-titles: true
      incremental: true
      include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
   beamer-cu:
      pdf-engine: xelatex
      aspectratio: 169
      fontsize: 9pt
      section-titles: true
      incremental: true
      include-in-header: ../files/xeheader_cu.tex   
      header-includes:
        - \newcommand{\cover}{../files/Методы вып_оптимизации_презентация_5.pdf}
---

# Условия оптимальности

## Важные понятия
$$
f(x) \to \min\limits_{x \in S}
$$

Множество $S$ обычно называется допустимым (бюджетным) множеством.

<!-- We say that the problem has a solution if the budget set is not empty: $x^* \in S$, in which the minimum or the infimum of the given function is achieved. -->


* Точка $x^*$ является глобальным минимумом, если $f(x^*) \leq f(x)$ для всех $x$.
* Точка $x^*$ является локальным минимумом, если существует окрестность $N$ точки $x^*$, такая что $f(x^*) \leq f(x)$ для всех $x \in N$.
* Точка $x^*$ является строгим локальным минимумом (также называется сильным локальным минимумом), если существует окрестность $N$ точки $x^*$, такая что $f(x^*) < f(x)$ для всех $x \in N$ с $x \neq x^*$.
* Мы называем точку $x^*$ стационарной (или критической), если $\nabla f(x^*) = 0$. Любой локальный минимум должен быть стационарной точкой.

![Illustration of different stationary (critical) points](../files/Local minima.pdf){width=150}


## Безусловная оптимизация

::: {.callout-tip title="Необходимое условие оптимальности первого порядка"}
Если $x^*$ является локальным минимумом и $f$ непрерывно дифференцируема в окрестности, то
$$
\nabla f(x^*) = 0
\tag{1}$$
::: 

::: {.callout-tip title="Достаточные условия оптимальности второго порядка"}
Предположим, что $\nabla^2 f$ непрерывна в окрестности точки $x^*$ и что
$$
\nabla f(x^*) = 0 \quad \nabla^2 f(x^*) \succ 0.
\tag{2}
$$
Тогда $x^*$ является строгим локальным минимумом функции $f$.
::: 


# Оптимизация с ограничениями-равенствами

## Оптимизация с ограничениями-равенствами

Рассмотрим простой, но практический случай ограничений-равенств:

$$
\begin{split}
    & f(x) \to \min\limits_{x \in \mathbb{R}^n} \\
    \text{s.t. } & h_i(x) = 0, i = 1, \ldots, p
\end{split}
$$

## Метод Лагранжа

Основная идея метода Лагранжа состоит в переходе от условной оптимизации к безусловной через увеличение размерности задачи:

$$
L(x, \nu) = f(x) + \sum\limits_{i=1}^p \nu_i h_i(x) =  f(x) + \nu^T h(x) \to \min\limits_{x \in \mathbb{R}^n, \nu \in \mathbb{R}^p}
$$

\
\

. . .

:::: {.columns}

::: {.column width="50%"}
::: {.callout-tip icon="false" appearance="simple"}

Необходимые условия:

$$
\nabla_x L(x^{*}, \nu^{*}) = 0
$$

$$
\nabla_{\nu} L(x^{*}, \nu^{*}) = 0
$$


:::
:::

::: {.column width="50%"}
::: {.callout-important icon="false" appearance="simple"}

Достаточные условия:


$$
\langle y , \nabla^{2}_{xx} L(x^{*}, \nu^{*}) y \rangle > 0, 
$$

$$
\forall y \neq 0 \in  \mathbb{R}^n: \nabla h_i(x^{*})^{T} y = 0
$$

:::
:::
::::

# Оптимизация с ограничениями-неравенствами

## Оптимизация с ограничениями-неравенствами

Рассмотрим простой, но практический случай ограничений-неравенств:

$$
\begin{split}
    & f(x) \to \min\limits_{x \in \mathbb{R}^n} \\
    \text{s.t. } & g(x) \leq 0
\end{split}
$$

. . .

:::: {.columns}

::: {.column width="50%"}

::: {.callout-tip icon="false" appearance="simple"}
$g(x) \leq 0$ **неактивно**. $g(x^*) < 0$:

$$g(x^*) < 0$$
$$\nabla f(x^*) = 0$$
$$\nabla^2 f(x^*) > 0$$
$$ $$
:::
:::

::: {.column width="50%"}

::: {.callout-tip icon="false" appearance="simple"}
$g(x) \leq 0$ **активно**. $g(x^*) = 0$:

$$g(x^*) = 0$$
$$- \nabla f(x^*) = \lambda \nabla g(x^*), \lambda > 0$$ 
$$\langle y, \nabla^2_{xx} L(x^*, \lambda^*) y \rangle > 0,$$
$$\forall y \neq 0 \in \mathbb{R}^n : \nabla g(x^*)^\top y = 0$$

:::
:::
::::


# Условия Каруша-Куна-Таккера

## Общая формулировка

Общая задача математического программирования:

$$
\begin{split}
& f_0(x) \to \min\limits_{x \in \mathbb{R}^n}\\
\text{s.t. } & f_i(x) \leq 0, \; i = 1,\ldots,m\\
& h_i(x) = 0, \; i = 1,\ldots, p
\end{split}
$$

. . .

Решение включает в себя построение функции Лагранжа:
$$
L(x, \lambda, \nu) = f_0(x) + \sum\limits_{i=1}^m \lambda_i f_i(x) + \sum\limits_{i=1}^p\nu_i h_i(x)
$$

## Необходимые условия ККТ

Пусть $x^*$, $(\lambda^*, \nu^*)$ является решением математической задачи программирования с нулевым двойственным разрывом (оптимальное значение для приоритетной задачи $p^*$ равно оптимальному значению для двойственной задачи $d^*$). Пусть также функции $f_0, f_i, h_i$ дифференцируемы.

. . .

::: {.callout-tip icon="false" appearance="simple"}
$$
\begin{split}
& (1) \nabla_x L(x^*, \lambda^*, \nu^*) = 0 \\
& (2) \nabla_\nu L(x^*, \lambda^*, \nu^*) = 0 \\
& (3) \lambda^*_i \geq 0, i = 1,\ldots,m \\
& (4) \lambda^*_i f_i(x^*) = 0, i = 1,\ldots,m \\
& (5) f_i(x^*) \leq 0, i = 1,\ldots,m \\
\end{split}
$$
:::

## Некоторые условия регулярности

Эти условия необходимы для того, чтобы условия ККТ стали необходимыми. Некоторые из них даже превращают необходимые условия в достаточные. Например, условие Слейтера:

\
\

. . .

::: {.callout-tip icon="false" appearance="simple"}

Если для выпуклой задачи (т.е., предполагая минимизацию, $f_0,f_{i}$ выпуклы и $h_{i}$ аффинны), существует точка $x$ такая что $h(x)=0$ и $f_{i}(x)<0$ (существование строго допустимой точки), то условия ККТ становятся необходимыми и достаточными.

:::

## Достаточные условия ККТ

Для гладких, нелинейных задач оптимизации, второе достаточное условие задается следующим образом. Решение $x^{*},\lambda ^{*},\nu ^{*}$, которое удовлетворяет условиям ККТ (выше), является локальным минимумом при ограничениях, если для функции Лагранжа

$$
L(x, \lambda, \nu) = f_0(x) + \sum\limits_{i=1}^m \lambda_i f_i(x) + \sum\limits_{i=1}^p\nu_i h_i(x)
$$

выполняются следующие условия:

::: {.callout-tip icon="false" appearance="simple"}
$$
\begin{split}
& \langle y , \nabla^2_{xx} L(x^*, \lambda^*, \nu^*) y \rangle > 0 \\
& \forall y \neq 0 \in \mathbb{R}^n : \nabla h_i(x^*)^\top y = 0, \nabla f_0(x^*) ^\top y \leq 0,\nabla f_j(x^*)^\top y = 0 \\
& i = 1,\ldots, p \quad \forall j: f_j(x^*) = 0
\end{split}
$$
:::

# Задачи

## Задача 1
::: {.callout-question title="Решить задачу оптимизации"}

Функция $f: E \to \mathbb{R}$ определена как 
$$f(x) = \ln \left( -Q(x) \right)$$ 
где $E = \{x \in \mathbb{R}^n : Q(x) < 0\}$ и 
$$Q(x) = \frac{1}{2} x^\top A x + b^\top x + c$$ 
с $A \in \mathbb{S}^n_{++}, \, b \in \mathbb{R}^n, \, c \in \mathbb{R}$.

Найдите точку максимума $x^*$ функции $f$.
::: 

## Задача 2
::: {.callout-question title="Решить задачу оптимизации"}

Найдите явное решение следующей задачи.
$$
\begin{split}
& f(x, y) = x + y \to \min\\
\text{s.t. } & x^2 + y^2 = 1
\end{split}
$$

где $x, y \in \mathbb{R}$.
::: 


## Задача 3
::: {.callout-question title="Решить задачу оптимизации"}

Найдите явное решение следующей задачи.
$$
\begin{split}
& \langle c, x \rangle + \sum_{i=1}^n x_i \log x_i \to \min\limits_{x \in \mathbb{R}^n }\\
\text{s.t. } & \sum_{i=1}^n x_i = 1,
\end{split}
$$
где $x\in\mathbb{R}^n_{++},c\neq 0$.
::: 


## Задача 4
::: {.callout-question title="Решить задачу оптимизации"}

Пусть $A\in\mathbb{S}_{++}^{n}, b>0$ покажите, что:

$$ 
\det(X) \to \max\limits_{X\in\mathbb{S}^{n}_{++}} \text{s.t.} \langle A,X \rangle \leq b
$$

имеет единственное решение и найдите его.

::: 


## Задача 5
::: {.callout-question title="Решить задачу оптимизации"}
Даны $y \in \{-1, 1\}$, и $X \in \mathbb{R}^{n \times p}$, задача об опорных векторах:

$$
\begin{split}
& \dfrac{1}{2} ||w||_{2}^{2} + C \sum_{i=1}^{n} \xi_i \to \min_{w, w_0, \xi_i}\\
\text{s.t. } & \xi_i  \geq 0, i = 1,\ldots, n \\
& y_i (x_i^{T} w + w_0) \geq 1 - \xi_i, i = 1,\ldots, n 
\end{split}
$$

найдите условие стационарности ККТ.
::: 

<!-- ## Задача 6 
::: {.callout-question title="Решить задачу оптимизации"}

Покажите, что следующая задача оптимизации с ограничениями имеет единственное решение и найдите его.

$$
\langle C^{-1}, X\rangle - \log \det(X) \to \min\limits_{X \in \mathbb{S}_{++}^{n}} \text{s.t. } a^T X a \leq 1 
$$

$C\in\mathbb{S}_{++}^n, a\neq 0$

Вы должны избежать явного обратного матрицы $C$ в ответе.
::: -->

<!-- ## Задача 7 (БОНУС)
Для некоторых $\Sigma,\Sigma_0\in\mathbb{S}^{n}_{++}$ определите расхождение Кульбака-Лейблера между двумя гауссовыми распределениями как:

$$
D(\Sigma, \Sigma_0) = \dfrac{1}{2}(\langle \Sigma^{-1}_{0}, \Sigma \rangle - \log \det(\Sigma^{-1}_{0}\Sigma) - n)
$$

Теперь пусть $H\in\mathbb{S}^{n}_{++}$ и $y,x \in \mathbb{R}^{n} : \langle y,s \rangle > 0$

Мы хотим решить следующую задачу минимизации с ограничениями.

$$
\min\limits_{X\in\mathbb{S}^{n}_{++}} \{D(X^{-1}, H^{-1}) | Xy=s\}
$$

Докажите, что она имеет единственное решение и оно равно:

$$
(I_n - \dfrac{sy^T}{y^{T}s})H(I_n - \dfrac{ys^{T}}{y^{T}s}) + \dfrac{ss^T}{y^{T}s}
$$

## Задача 8 (БОНУС)
::: {.callout-question title="Решить задачу оптимизации"}
Пусть $e_1,\dots,e_n$ будет стандартным базисом в $\mathbb{R}^{n}$. Покажите, что:

$$ 
\max\limits_{X\in\mathbb{S}^{n}_{++}} {\det(X): ||Xe_i|| \leq 1 \forall i \in 1,\dots,n} 
$$

имеет единственное решение $I_n$, и выведите неравенство Гильберта:

$$ 
\det(X) \leq \prod\limits_{i=1}^{n} ||Xe_i|| \forall X \in \mathbb{S}^{n}_{++} 
$$

:::  -->

# Приложения
## Адверсариальные атаки
**Определение**: Адверсариальные атаки используются для обмана моделей DL путем добавления небольших возмущений к входным данным. Мы можем сформулировать это как задачу оптимизации с ограничениями, где целью является минимизация/максимизация функции потерь при сохранении возмущения в определенных пределах (ограничение нормы).

Метод FGSM (fast gradient-sign method) является самым простым таким методом, который генерирует adversarial examples путем применения небольшого возмущения в направлении градиента функции потерь. Формально:
$$
x' = x + \varepsilon \cdot \text{sgn}(\nabla_x L(x, y)), \text{s.t. }||x - x'||\leq \varepsilon
$$

Таким образом, мы выполняем градиентный подъем на изображении (== максимизация потерь по отношению к этому изображению).

![Иллюстрация](../files/adversarial_attacks_cat_ex.pdf){width=150}

Вот код, попробуйте его сами! [\faPython](https://colab.research.google.com/drive/1_jMb7TJUrh48JHRGisw6fNlPth7NJlTT?usp=sharing)


