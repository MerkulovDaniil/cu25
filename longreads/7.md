---
title: "Градиентный спуск. Теоремы сходимости в гладком случае (выпуклые, сильно выпуклые, PL). Верхние и нижние оценки сходимости."
author: Даня Меркулов
institute: Оптимизация для всех! ЦУ
format:
    pdf:
        include-in-header: ../files/longread_header.tex
        keep-tex: true
number-sections: true
---

# Градиентный спуск

## Направление локального наискорейшего спуска

:::: {.columns}

::: {.column width="40%"}
Рассмотрим линейное приближение дифференцируемой функции $f$ вдоль направления $h$, где $\|h\|_2 = 1$:

$$
f(x + \alpha h) = f(x) + \alpha \langle \nabla f(x), h \rangle + o(\alpha)
$$

Хотим, чтобы $h$ было направлением убывания:
$$
f(x + \alpha h) < f(x)
$$
$$
f(x) + \alpha \langle \nabla f(x), h \rangle + o(\alpha) < f(x)
$$


Переходя к пределу при $\alpha \to 0$:
$$
\langle \nabla f(x), h \rangle \leq 0
$$
:::


::: {.column width="60%"}

Также из неравенства Коши–Буняковского получаем:
$$
\begin{split}
|\langle \nabla f(x), h \rangle | &\leq \| \nabla f(x) \|_2 \| h \|_2 \\
\langle \nabla f(x), h \rangle &\geq -\| \nabla f(x) \|_2 \| h \|_2 = -\| \nabla f(x) \|_2
\end{split}
$$


Таким образом, направление антиградиента
$$
h = -\dfrac{\nabla f(x)}{\|\nabla f(x)\|_2}
$$
представляет собой направление **наискорейшего локального** убывания функции $f$.



Итерация метода имеет вид:
$$
x^{k+1} = x^k - \alpha \, \nabla f(x^k)
$$

:::
::::

## Дифференциальное уравнение градиентного потока

:::: {.columns}
::: {.column width="78%"}

Рассмотрим дифференциальное уравнение градиентного потока:
$$
\tag{GF}
\frac{dx}{dt} = -\nabla f(x(t)).
$$


Дискретизируем его на равномерной сетке с шагом $\alpha$:
$$
\frac{x^{k+1} - x^k}{\alpha} = -\nabla f(x^k),
$$


где $x^k \equiv x(t_k)$ и $\alpha = t_{k+1} - t_k$ — шаг сетки.

Отсюда получаем выражение для $x^{k+1}$:
$$
x^{k+1} = x^k - \alpha \, \nabla f(x^k),
$$
являющееся точной формулой обновления градиентного спуска.

[Открыть в Colab $\clubsuit$](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/GD_vs_GF.ipynb)
:::



::: {.column width="22%"}
![Траектория градиентного потока](GD_vs_GF.pdf)
:::
::::

## Сходимость алгоритма градиентного спуска

[\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/GD_2d_visualization.ipynb) для построения анимации ниже. Сходимость существенно зависит от выбора шага $\alpha$:

[![](gd_2d.png)](https://fmin.xyz/docs/visualizations/gd_lls.mp4)


## Точный линейный поиск (метод наискорейшего спуска)

:::: {.columns}
::: {.column width="80%"}
$$
\alpha_k = \operatorname*{arg\,min}_{\alpha \in \mathbb{R}^+} f\bigl(x^k - \alpha \, \nabla f(x^k)\bigr)
$$
Подход скорее теоретический, чем практический: он удобен для анализа сходимости, но точный линейный поиск часто затруднён, если вычисление функции занимает слишком много времени или стоит слишком дорого.

Интересное теоретическое свойство этого метода заключается в том, что градиенты на соседних итерациях ортогональны. Условие оптимальности по $\alpha_k$ даёт
$$
\left.\dfrac{d}{d\alpha} \, f\bigl(x^k - \alpha \, \nabla f(x^k)\bigr)\right|_{\alpha = \alpha_k} = 0.
$$


Условия оптимальности:


$$
\nabla f(x^{k+1})^\top \nabla f(x^k) = 0
$$

:::
::: {.column width="20%"}

![Наискорейший спуск](GD_vs_Steepest.pdf)

[Открыть в Colab $\clubsuit$](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/Steepest_descent.ipynb)
:::
::::

# Сильно выпуклые квадратичные функции

## Сдвиг координат

:::: {.columns}

::: {.column width="70%"}

Рассмотрим следующую задачу квадратичной оптимизации:
$$
\label{problem}
\min\limits_{x \in \mathbb{R}^d} f(x) =  \min\limits_{x \in \mathbb{R}^d} \dfrac{1}{2} x^\top  A x - b^\top  x + c, \text{ где } A \in \mathbb{S}^d_{++}.
$$


* Во-первых, без ограничения общности мы можем установить $c = 0$, что не повлияет на процесс оптимизации.
* Во-вторых, у нас есть спектральное разложение матрицы $A = Q \Lambda Q^T$.
* Покажем, что мы можем сделать сдвиг координат, чтобы сделать анализ немного проще. Пусть $\hat{x} = Q^T(x - x^*)$, где $x^*$ — точка минимума исходной функции, определяемая как $Ax^* = b$. При этом $x = Q\hat{x} + x^*$.
    $$
    \begin{split}
     f(\hat{x}) &= \frac12  (Q\hat{x} + x^*)^\top  A (Q\hat{x} + x^*) - b^\top  (Q\hat{x} + x^*) \\
     &= \frac12 \hat{x}^T Q^TAQ\hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - b^T Q\hat{x} - b^T x^*\\
     &= \frac12 \hat{x}^T \Lambda \hat{x} + \frac12 (x^*)^T A (x^*) + (x^*)^TAQ\hat{x} - (x^*)^T A^TQ\hat{x} - (x^*)^T A x^*\\
    &= \frac12 \hat{x}^T \Lambda \hat{x} - \frac12 (x^*)^T A x^* \simeq \frac12 \hat{x}^T \Lambda \hat{x} 
    \end{split}
    $$

:::
::: {.column width="30%"}
![](coordinate_shift.pdf)
:::
::::

## Анализ сходимости

Теперь мы можем работать с функцией $f(x) = \frac12 x^T \Lambda x$ с $x^* = 0$ без ограничения общности (убрав крышку из $\hat{x}$)

:::: {.columns}
::: {.column width="50%"}
$$
\begin{split}
x^{k+1} &= x^k - \alpha^k \nabla f(x^k)
= x^k - \alpha^k \Lambda x^k \\  
&= (I - \alpha^k \Lambda) x^k \\ 
x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)}) \, x^k_{(i)} \quad \text{для $i$-й координаты} \\ 
x^{k}_{(i)} &= (1 - \alpha \, \lambda_{(i)})^k \, x^0_{(i)} \quad \text{при постоянном шаге } \alpha^k = \alpha
\end{split}
$$

Используем постоянный шаг $\alpha^k = \alpha$. Условие сходимости:
$$
\rho(\alpha) = \max_{i} |1 - \alpha \lambda_{(i)}| < 1
$$


Помним, что $\lambda_{\min} = \mu > 0$, $\lambda_{\max} = L \geq \mu$.

:::: {.columns}

::: {.column width="50%"}
$$
\begin{split}
|1 - \alpha \mu| &< 1 \\ 
 -1 < 1 &- \alpha \mu < 1 \\ 
 \alpha < \tfrac{2}{\mu} \quad & \quad \alpha\mu > 0
\end{split}
$$
:::

::: {.column width="50%"}

$$
\begin{split}
|1 - \alpha L| &< 1 \\ 
 -1 < 1 &- \alpha L < 1 \\ 
 \alpha < \tfrac{2}{L} \quad & \quad \alpha L > 0
\end{split}
$$
:::
::::

:::


::: {.column width="50%"}
Выберем $\alpha$, минимизирующий худший знаменатель прогрессии
$$
\begin{split}
\rho^* &=  \min_{\alpha} \rho(\alpha)   = \min_{\alpha} \max_{i} |1 - \alpha \lambda_{(i)}| \\ 
 &=  \min_{\alpha} \left\{|1 - \alpha \mu|, |1 - \alpha L| \right\} \\ 
\alpha^* &: \quad  1 - \alpha^* \mu = \alpha^* L - 1 \\ 
 & \alpha^* = \frac{2}{\mu + L}  \quad \rho^* = \frac{L - \mu}{L + \mu} \\ 
 |x^{k}_{(i)}| &\leq \left( \frac{L - \mu}{L + \mu} \right)^k |x^0_{(i)}| \\
 \|x^{k}\|_2 &\leq \left( \frac{L - \mu}{L + \mu} \right)^k \|x^0\|_2  \quad f(x^{k}) \leq \left( \frac{L - \mu}{L + \mu} \right)^{2k} f(x^0)
\end{split}
$$
:::
::::


Таким образом, имеем линейную сходимость по аргументу со скоростью $\frac{\varkappa - 1}{\varkappa + 1} = 1 - \frac{2}{\varkappa + 1}$, где $\varkappa = \frac{L}{\mu}$ — *число обусловленности* квадратичной задачи.

| $\varkappa$ | $\rho$ | Итераций до уменьшения ошибки по аргументу в $10$ раз | Итераций до уменьшения ошибки по функции в $10$ раз |
|:-:|:-:|:-----------:|:-----------:|
| $1.1$ | $0.05$ | $1$ | $1$ |
| $2$ | $0.33$ | $3$ | $2$ |
| $5$ | $0.67$ | $6$ | $3$ |
| $10$ | $0.82$ | $12$ | $6$ |
| $50$ | $0.96$ | $58$ | $29$ |
| $100$ | $0.98$ | $116$ | $58$ |
| $500$ | $0.996$ | $576$ | $288$ |
| $1000$ | $0.998$ | $1152$ | $576$ |

## Число обусловленности $\varkappa$

[![](condition_number_gd.pdf)](https://fmin.xyz/docs/visualizations/condition_number_gd.mp4)

# Случай PL-функций

## PL-функции. Линейная сходимость градиентного спуска без выпуклости

Говорят, что $f$ удовлетворяет условию Поляка-Лоясиевича (PL), если для некоторого $\mu > 0$ выполняется
$$
\Vert \nabla f(x) \Vert^2 \geq 2 \mu (f(x) - f^*) \quad \forall x
$$
Интересно, что градиентный спуск может сходиться линейно даже без выпуклости.

Следующие функции удовлетворяют условию PL, но не являются выпуклыми. [\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/PL_function.ipynb)

:::: {.columns}

::: {.column width="50%"}

$$
f(x) = x^2 + 3\sin^2(x)
$$

![PL-функция](pl_2d.pdf){width=50%}

:::


::: {.column width="50%"}

$$
f(x,y) = \dfrac{(y - \sin x)^2}{2}
$$

![PL-функция](pl_3d.pdf){width=50%}

:::
::::

## Анализ сходимости

:::{.callout-theorem}
Рассмотрим задачу
$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$
и предположим, что $f$ является PL-функцией с константой $\mu$ и $L$-гладкой, для некоторых $L\geq \mu > 0$.

Рассмотрим последовательность $(x^k)_{k \in \mathbb{N}}$, сгенерированную методом градиентного спуска из точки $x^0$ с постоянным шагом $\alpha$, удовлетворяющим $0<\alpha \leq \frac{1}{L}$. Пусть $f^* = \min\limits_{x \in \mathbb{R}^d} f(x)$. Тогда:
$$
f(x^{k})-f^* \leq (1-\alpha \mu)^k (f(x^0)-f^*).
$$
:::


Используем $L$-гладкость вместе с правилом обновления, чтобы записать:
$$
\begin{split}
 f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\ 
 &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\ 
 &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\ 
 & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2,
\end{split}
$$


где в последнем неравенстве использована гипотеза о шаге $\alpha L \leq 1$.


Теперь используем свойство PL-функции и получаем:
$$
f(x^{k+1}) \leq f(x^{k}) - \alpha \mu (f(x^{k}) - f^*).
$$
Вычтя $f^*$ из обеих частей этого неравенства и применив рекурсию, мы получим искомый результат.

## Любая $\mu$-сильно выпуклая дифференцируемая функция является PL-функцией

:::{.callout-theorem}
Если функция $f(x)$ дифференцируема и $\mu$-сильно выпукла, то она является PL-функцией.
:::

**Доказательство**

:::: {.columns}

::: {.column width="60%"}

По критерию сильной выпуклости первого порядка:
$$
f(y) \geq f(x) + \nabla f(x)^T(y-x) + \tfrac{\mu}{2}\|y-x\|_2^2
$$
Положим $y = x^*$:
$$
\begin{split}
 f(x^*) &\geq f(x) + \nabla f(x)^T(x^*-x) + \tfrac{\mu}{2}\|x^*-x\|_2^2 \\ 
f(x) - f(x^*) &\leq \nabla f(x)^T(x-x^*) - \tfrac{\mu}{2}\|x^*-x\|_2^2 = \\ 
&= \left(\nabla f(x)^T - \tfrac{\mu}{2}(x^*-x)\right)^T (x-x^*) = \\ 
&= \frac12 \left(\tfrac{2}{\sqrt{\mu}}\nabla f(x)^T - \sqrt{\mu}(x^*-x)\right)^T \sqrt{\mu}(x-x^*)\\ 
\end{split}
$$
:::


::: {.column width="40%"}

Пусть $a = \frac{1}{\sqrt{\mu}}\nabla f(x)$ и $b =\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)$ 


Тогда $a+b = \sqrt{\mu}(x-x^*)$ и $a-b=\frac{2}{\sqrt{\mu}}\nabla f(x)-\sqrt{\mu}(x-x^*)$
:::
::::


$$
\begin{split}
f(x) - f(x^*) &\leq \frac12 \left(\frac{1}{\mu}\|\nabla f(x)\|^2_2 - \left\|\sqrt{\mu}(x-x^*) -\frac{1}{\sqrt{\mu}}\nabla f(x)\right\|_2^2\right) \\ 
    f(x) - f(x^*) &\leq \frac{1}{2\mu}\|\nabla f(x)\|^2_2, \\ 
    \end{split}
    $$


которое является точным условием PL. Это означает, что мы уже имеем доказательство линейной сходимости для любой сильно выпуклой функции.

# Выпуклый гладкий случай


:::{.callout-theorem}
Рассмотрим задачу
$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$
и предположим, что $f$ является выпуклой и $L$-гладкой функцией, для некоторого $L>0$.

Пусть $(x^{k})_{k \in \mathbb{N}}$ — последовательность итераций, сгенерированная методом градиентного спуска из точки $x^0$ с постоянным шагом $\alpha$, удовлетворяющим $0 < \alpha\leq \frac{1}{L}$. Пусть $f^* = \min\limits_{x \in \mathbb{R}^d} f(x)$. Тогда для всех $x^* \in \operatorname*{arg\,min}\, f$ и всех $k \in \mathbb{N}$ справедливо:
$$
f(x^{k})-f^* \leq \frac{\|x^0-x^*\| ^2}{2 \alpha k}.
$$
:::

## Анализ сходимости

* Как и раньше, сначала используем гладкость:
    $$
    \begin{split}
     f(x^{k+1})& \leq f(x^{k}) + \langle \nabla f(x^{k}), x^{k+1}-x^{k} \rangle +\frac{L}{2} \| x^{k+1}-x^{k}\|^2\\ 
     &= f(x^{k})-\alpha\Vert \nabla f(x^{k}) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^{k})\|^2 \\ 
     &= f(x^{k}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^{k}) \Vert^2 \\ 
     & \leq f(x^{k}) - \frac{\alpha}{2}\Vert \nabla f(x^{k})\Vert^2, \\ 
     f(x^{k}) - f(x^{k+1}) & \geq \dfrac{1}{2L} \Vert \nabla f(x^{k})\Vert^2 \quad \text{если } \alpha = \tfrac1L 
    \end{split}
    $$ {#eq-gd-cs-smoothness}


    Обычно для сходящегося градиентного спуска чем больше допустимый шаг, тем быстрее сходимость, поэтому часто берут $\alpha = \tfrac1L$.
 * После этого используем выпуклость:
    $$
    \begin{split}
    f(y) &\geq f(x) + \langle \nabla f(x), y-x\rangle \text{ где } y = x^*, x = x^k\\
    f(x^k) - f^* &\leq \langle \nabla f(x^k), x^k-x^*\rangle 
    \end{split}
    $$ {#eq-gd-cs-convexity}


* Теперь подставляем (-@eq-gd-cs-convexity) в (-@eq-gd-cs-smoothness):
    $$
    \begin{split}
    f(x^{k+1}) &\leq f(x^{k}) -\frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \leq f^* + \langle \nabla f(x^k), x^k-x^*\rangle - \frac{\alpha}{2} \Vert \nabla f(x^{k})\Vert^2 \\ 
    &= f^* + \langle \nabla f(x^k), x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\rangle \\ 
    &= f^* + \frac{1}{2 \alpha}\left\langle \alpha \nabla f(x^k), 2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)\right\rangle 
    \end{split}
    $$
    Пусть $a = x^k-x^*$ и $b = x^k-x^* - \alpha\nabla f(x^k)$. Тогда $a+b = \alpha \nabla f(x^k)$ и $a-b=2\left(x^k-x^* - \frac{\alpha}{2} \nabla f(x^{k})\right)$.
    $$
    \begin{split}
    f(x^{k+1}) &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^k-x^* - \alpha\nabla f(x^k)\|_2^2\right] \\ 
    &\leq f^* + \frac{1}{2 \alpha}\left[ \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2\right] \\ 
    2\alpha \left(f(x^{k+1}) - f^*\right) &\leq \|x^k-x^*\|_2^2 - \|x^{k+1}-x^*\|_2^2 
    \end{split}
    $$
* Просуммируем по $i = 0,\dots, k-1$. Большинство слагаемых обнуляется из-за телескопической суммы:
    $$
    \begin{split}
    2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right) &\leq \|x^0-x^*\|_2^2 - \|x^{k}-x^*\|_2^2 \leq \|x^0-x^*\|_2^2 
    \end{split}
    $$ {#eq-gd-sc-telescopic}


* Поскольку на каждой итерации $f(x^{i+1}) \leq f(x^i)$, то
    $$
    kf(x^k) \leq \sum\limits_{i=0}^{k-1}f(x^{i+1})
    $$
* Теперь подставим это в (-@eq-gd-sc-telescopic):
    $$
    \begin{split}
    2\alpha kf(x^k) - 2\alpha kf^* &\leq 2\alpha \sum\limits_{i=0}^{k-1} \left(f(x^{i+1}) - f^*\right)  \leq \|x^0-x^*\|_2^2 \\ 
     f(x^k) - f^* &\leq \frac{\|x^0-x^*\|_2^2}{2 \alpha k} \leq  \frac{L \|x^0-x^*\|_2^2}{2 k} 
    \end{split}
    $$

\newpage

## Итог

$$
\text{Градиентный спуск:} \qquad \qquad \min_{x \in \mathbb{R}^n} f(x) \qquad \qquad x^{k+1} = x^k - \alpha^k \nabla f(x^k)
$$



| гладкий (не выпуклый) | гладкий и выпуклый | гладкий и сильно выпуклый (или PL) |
|:-----:|:-----:|:--------:|
| $\|\nabla f(x^k)\|^2 \sim \mathcal{O} \left( \dfrac{1}{k} \right)$ | $f(x^k) - f^* \sim  \mathcal{O} \left( \dfrac{1}{k} \right)$ | $\|x^k - x^*\|^2 \sim \mathcal{O} \left( \left(1 - \dfrac{\mu}{L}\right)^k \right)$ |
| $k_\varepsilon \sim \mathcal{O} \left( \dfrac{1}{\varepsilon} \right)$ | $k_\varepsilon \sim  \mathcal{O}  \left( \dfrac{1}{\varepsilon} \right)$ | $k_\varepsilon  \sim \mathcal{O} \left( \varkappa \log \dfrac{1}{\varepsilon}\right)$ |

## Численные эксперименты

$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_0.001_100_60.pdf)


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_10_100_60.pdf)


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_random_10_1000_60.pdf)


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_clustered_10_1000_60.pdf)


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_clustered_10_1000_600.pdf)


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![]("gd_uniform spectrum_1_100_60.pdf")


$$
f(x) = \frac{1}{2} x^T A x - b^T x \to \min_{x \in \mathbb{R}^n}
$$

![](gd_Hilbert_1_10_60.pdf)


$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![]("GD 0.07GD 0.9GD 10.0_0.pdf"){fig-align="center" width=95%}


$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![]("GD 0.12GD 0.14GD 0.15_0.1.pdf"){fig-align="center" width=95%}


$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![](gd_non_linear_1000_300_0_None.pdf)


$$
f(x) = \frac{\mu}{2} \|x\|_2^2 + \frac1m \sum_{i=1}^m \log (1 + \exp(- y_i \langle a_i, x \rangle)) \to \min_{x \in \mathbb{R}^n}
$$

![](gd_non_linear_1000_300_1_None.pdf)

# Задачи

Рассмотрим задачу
$$
    \min_{x \in \mathbb R^n} f(x),
$$
где $f(x)$ выпукла и $L$-гладкая. Найдите скорость сходимости градиентного спуска с оптимальным теоретическим шагом $\eta_k = \frac{1}{L}$ для \textit{усредненной точки} и для \textit{лучшей точки}. 
Другими словами, получите верхние границы на 

- $f(\bar{x}_N) - f^*,\ \text{where}\ \bar{x}_N = \frac{1}{N} \sum_{i=0}^{N-1} x_i$, 
- $\min_{0 \le i \le N-1} f(x_i) - f^*$.

:::{.callout-note}
## Шаг градиентного спуска
$$
x_{k + 1} = \arg \min_{x \in \mathbb R^n} \left\{ \Psi_k(x) \equiv f(x_k) + \langle \nabla f(x_k), x - x_k \rangle + \frac{L}{2} \| x - x_k \|_2^2 \right\}
$$
:::


:::{.callout-tip}
## Совет
Используйте факт, что $\Psi_k(x)$ является $L$-строго выпуклой из-за квадратичного регуляризатора.
:::

# Задачи на дом

## **Сходимость градиентного спуска в невыпуклом гладком случае** [10 баллов]

Мы не будем делать никаких предположений о выпуклости функции $f$. Мы покажем, что градиентный спуск достигает $\varepsilon$-стационарной точки $x$, такой что $\|\nabla f(x)\|_2 \leq \varepsilon$, за $O(1/\varepsilon^2)$ итераций. Важное замечание: вы можете использовать здесь липшицеву параболическую верхнюю оценку: 
    
$$
f(y) \leq f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \|y-x\|_2^2, \;\;\;
\text{for all $x,y$}.  
$$ {#eq-quad_ub}

* Подставьте $y = x^{k+1} = x^{k} - \alpha \nabla f(x^k), x = x^k$ в (@eq-quad_ub) чтобы показать, что 

    $$
    f(x^{k+1}) \leq f(x^k) - \Big (1-\frac{L\alpha}{2} \Big) \alpha \|\nabla f(x^k)\|_2^2.
    $$

* Используйте $\alpha \leq 1/L$, и преобразуйте предыдущий результат, чтобы получить 

    $$
    \|\nabla f(x^k)\|_2^2 \leq \frac{2}{\alpha} \left( f(x^k) - f(x^{k+1}) \right).
    $$

* Просуммируйте предыдущий результат по всем итерациям от $1,\ldots,k+1$ чтобы получить
    
    $$
    \sum_{i=0}^k \|\nabla f(x^{i})\|_2^2 \leq 
    \frac{2}{\alpha} ( f(x^{0}) - f^*).
    $$

* Дайте нижнюю оценку сумме в предыдущем результате, чтобы получить 

    $$
    \min_{i=0,\ldots,k} \|\nabla f(x^{i}) \|_2 
    \leq \sqrt{\frac{2}{\alpha(k+1)} (f(x^{0}) - f^*)}, 
    $$
что устанавливает желаемую скорость $O(1/\varepsilon^2)$ для достижения $\varepsilon$-стационарности.  

## **Как сходится градиентный спуск в зависимости от числа обусловленности и размерности.** [20 баллов] 

Исследуйте, как количество итераций, необходимое для сходимости градиентного спуска, зависит от следующих двух параметров: числа обусловленности $\kappa \geq 1$ функции, которую мы оптимизируем, и размерности $n$ пространства переменных, по которым мы оптимизируем.
    
Для этого при заданных параметрах $n$ и $\kappa$ случайно сгенерируйте квадратичную задачу размера $n$ с числом обусловленности $\kappa$ и запустите на ней градиентный спуск с заранее заданной фиксированной точностью. Измерьте число итераций $T(n,\kappa)$, которое потребовалось методу для сходимости (успешного завершения по критерию останова).

Рекомендация: самый простой способ сгенерировать случайную квадратичную задачу размера $n$ с заданным числом обусловленности $\kappa$ следующий -  удобно взять диагональную матрицу $A \in S_{n}^{++}$ в виде $A = \text{Diag}(a)$, где диагональные элементы случайно выбираются из интервала $[1, \kappa]$ и удовлетворяют $\min(a) = 1$, $\max(a) = \kappa$. В качестве вектора $b \in \mathbb{R}^n$ можно взять вектор со случайными компонентами. Диагональные матрицы удобны для рассмотрения, поскольку их можно эффективно обрабатывать даже при больших значениях $n$.

Зафиксируйте определенное значение размерности $n$. Итерируйте по различным числам обусловленности $\kappa$ на сетке и постройте зависимость $T(n,\kappa)$ от $\kappa$. Поскольку квадратичная задача каждый раз генерируется случайно, повторите этот эксперимент несколько раз. В результате для фиксированного значения $n$ вы должны получить семейство кривых, показывающих зависимость $T(n, \kappa)$ от $\kappa$. Изобразите все эти кривые в одном цвете для ясности (например, красный).

Увеличьте значение $n$ и повторите эксперимент. Вы должны получить новое семейство кривых $T(n',\kappa)$ от $\kappa$. Изобразите все эти кривые в одном цвете, но отличающемся от предыдущего (например, синий).

Повторите эту процедуру несколько раз для других значений $n$. В итоге вы должны получить несколько разных семейств кривых - некоторые красные (соответствующие одному значению $n$), некоторые синие (соответствующие другому значению $n$), некоторые зеленые и т.д.

Обратите внимание, что имеет смысл перебирать значения размерности $n$ по логарифмической сетке (например, $n = 10$, $n = 100$, $n = 1000$ и т. д.). Используйте следующий критерий остановки: $\|\nabla f(x_k)\|_2^2 \leq \varepsilon \|\nabla f(x_0)\|_2^2$ при $\varepsilon = 10^{-5}$. В качестве начальной точки возьмите $x_0 = (1, \ldots, 1)^T$.

Какие выводы можно сделать из полученного рисунка?

